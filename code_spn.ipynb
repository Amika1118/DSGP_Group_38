{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4c04ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PROFESSIONAL SPN IMPLEMENTATION WITH REAL PRICE INTEGRATION\n",
      "Using Dambulla wholesale & Colombo market historical data\n",
      "======================================================================\n",
      "\n",
      "1. LOADING AND PREPARING DATA\n",
      "Loaded 166 vegetables with 6 nutrients\n",
      "Training handcrafted SPN...\n",
      "Building handcrafted SPN for nutrition...\n",
      "Built SPN with 18 nodes\n",
      "\n",
      "2. GENERATING RECOMMENDATIONS\n",
      "User Profile: {'Energy (kcal)': 80.0, 'Protein (g)': 2.5, 'Fiber (g)': 3.5, 'Iron (mg)': 1.8, 'Potassium (mg)': 350.0, 'Vitamin C (mg)': 40.0}\n",
      "\n",
      "Top Recommendations (with real prices):\n",
      "1. ACEROLA JUICE,RAW\n",
      "   Probability: 0.0000\n",
      "   Est. Price per unit: LKR 129.29\n",
      "2. ROSELLE,RAW\n",
      "   Probability: 0.0000\n",
      "   Est. Price per unit: LKR 129.29\n",
      "3. AMARANTH LEAVES,RAW\n",
      "   Probability: 0.0000\n",
      "   Est. Price per unit: LKR 129.29\n",
      "\n",
      "3. SPN EXPLANATION FOR TOP RECOMMENDATION\n",
      "Vegetable: ACEROLA JUICE,RAW\n",
      "SPN Probability: 0.0000\n",
      "Estimated Price: LKR 129.29\n",
      "SPN Confidence: 0.0000\n",
      "\n",
      "======================================================================\n",
      "SPN DEMO COMPLETE – REAL PRICES INTEGRATED\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple, Optional, Any, Set\n",
    "from collections import defaultdict, deque\n",
    "import json\n",
    "import math\n",
    "from scipy.special import logsumexp\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load new price datasets\n",
    "wholesale_df = pd.read_csv('wholesale historical data.csv')\n",
    "market_df = pd.read_csv('vegetable_prices_pruned_features.csv')\n",
    "\n",
    "# PRICE LOOKUP FUNCTION (updated for real datasets)\n",
    "def get_real_price(veg_name, month=None, year=None):\n",
    "    if month is None or year is None:\n",
    "        now = datetime.now(ZoneInfo(\"Asia/Colombo\"))\n",
    "        month = now.month\n",
    "        year = now.year\n",
    "    \n",
    "    veg_name = veg_name.split(',')[0].upper() if ',' in veg_name else veg_name.upper()\n",
    "    \n",
    "    # Try Dambulla wholesale first (primary source)\n",
    "    wholesale_match = wholesale_df[\n",
    "        (wholesale_df['Vegetable_Name'].str.upper() == veg_name) &\n",
    "        (wholesale_df['Month'] == month) & (wholesale_df['ISO_Year'] == year)\n",
    "    ]\n",
    "    if not wholesale_match.empty:\n",
    "        return wholesale_match['Avg_Weekly_Price'].mean()\n",
    "    \n",
    "    # Fallback to Colombo market prices\n",
    "    market_match = market_df[\n",
    "        (market_df['Vegetable'].str.upper() == veg_name) &\n",
    "        (market_df['Month'] == month) & (market_df['Year'] == year)\n",
    "    ]\n",
    "    if not market_match.empty:\n",
    "        return market_match['Weekly_Price'].mean()\n",
    "    \n",
    "    # Final fallback to CotD base (approx daily)\n",
    "    return 905.0 / 7\n",
    "\n",
    "# ============================================================================\n",
    "# 1. PROFESSIONAL SPN IMPLEMENTATION WITH ACADEMIC CORRECTNESS\n",
    "# ============================================================================\n",
    "class SPNNode:\n",
    "    \"\"\"Base class for all SPN nodes with proper scope management\"\"\"\n",
    "    def __init__(self, scope: List[int]):\n",
    "        self.scope = sorted(scope)\n",
    "        self.value = 0.0\n",
    "        self.gradient = 0.0\n",
    "        self.parents: List[SPNNode] = []\n",
    "        self.id = id(self)\n",
    "       \n",
    "    def forward(self, X: np.ndarray, log_space: bool = True) -> float:\n",
    "        raise NotImplementedError\n",
    "       \n",
    "    def backward(self, grad: float):\n",
    "        raise NotImplementedError\n",
    "       \n",
    "    def sample(self, evidence: Optional[Dict[int, float]] = None) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "       \n",
    "    def marginals(self, X: np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "       \n",
    "    def mpe(self, evidence: Dict[int, float]) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class LeafNode(SPNNode):\n",
    "    \"\"\"Leaf node with proper EM parameter learning\"\"\"\n",
    "    def __init__(self, scope: List[int], dist_type: str = 'gaussian'):\n",
    "        assert len(scope) == 1, \"Leaf nodes must have exactly 1 variable in scope\"\n",
    "        super().__init__(scope)\n",
    "        self.dist_type = dist_type\n",
    "        self.mean = 0.0\n",
    "        self.std = 1.0\n",
    "        self.var_idx = scope[0]\n",
    "       \n",
    "        self.sum_resp = 0.0\n",
    "        self.sum_x = 0.0\n",
    "        self.sum_x2 = 0.0\n",
    "       \n",
    "    def forward(self, X: np.ndarray, log_space: bool = True) -> float:\n",
    "        x_val = X[self.var_idx]\n",
    "        if np.isnan(x_val):\n",
    "            return 0.0\n",
    "       \n",
    "        if self.dist_type == 'gaussian':\n",
    "            z = (x_val - self.mean) / max(self.std, 1e-8)\n",
    "            log_pdf = -0.5 * (z ** 2 + np.log(2 * np.pi * self.std ** 2 + 1e-8))\n",
    "            return log_pdf if log_space else np.exp(log_pdf)\n",
    "        else:\n",
    "            return 0.0\n",
    "           \n",
    "    def collect_statistics(self, X: np.ndarray, responsibility: float):\n",
    "        x_val = X[self.var_idx]\n",
    "        if not np.isnan(x_val):\n",
    "            self.sum_resp += responsibility\n",
    "            self.sum_x += responsibility * x_val\n",
    "            self.sum_x2 += responsibility * x_val * x_val\n",
    "           \n",
    "    def update_parameters(self):\n",
    "        if self.sum_resp > 1e-8 and self.dist_type == 'gaussian':\n",
    "            self.mean = self.sum_x / self.sum_resp\n",
    "            var = max(self.sum_x2 / self.sum_resp - self.mean ** 2, 1e-8)\n",
    "            self.std = np.sqrt(var)\n",
    "        self.sum_resp = self.sum_x = self.sum_x2 = 0.0\n",
    "       \n",
    "    def sample(self, evidence: Optional[Dict[int, float]] = None) -> np.ndarray:\n",
    "        if evidence and self.var_idx in evidence:\n",
    "            return np.array([evidence[self.var_idx]])\n",
    "        return np.random.normal(self.mean, self.std, 1)\n",
    "           \n",
    "    def mpe(self, evidence: Dict[int, float]) -> np.ndarray:\n",
    "        return np.array([self.mean])\n",
    "\n",
    "class ProductNode(SPNNode):\n",
    "    def __init__(self, children: List[SPNNode]):\n",
    "        all_scopes = []\n",
    "        for child in children:\n",
    "            all_scopes.extend(child.scope)\n",
    "            child.parents.append(self)\n",
    "           \n",
    "        if len(all_scopes) != len(set(all_scopes)):\n",
    "            raise ValueError(\"Product node children must have DISJOINT scopes!\")\n",
    "           \n",
    "        super().__init__(sorted(set(all_scopes)))\n",
    "        self.children = children\n",
    "       \n",
    "    def forward(self, X: np.ndarray, log_space: bool = True) -> float:\n",
    "        log_prob = 0.0\n",
    "        for child in self.children:\n",
    "            log_prob += child.forward(X, log_space)\n",
    "        return log_prob\n",
    "       \n",
    "    def sample(self, evidence=None) -> np.ndarray:\n",
    "        sample_dict = {}\n",
    "        for child in self.children:\n",
    "            child_sample = child.sample(evidence)\n",
    "            for i, var_idx in enumerate(child.scope):\n",
    "                if var_idx not in sample_dict:\n",
    "                    sample_dict[var_idx] = child_sample[i] if len(child_sample) > i else child_sample\n",
    "        result = np.zeros(len(self.scope))\n",
    "        for i, var_idx in enumerate(self.scope):\n",
    "            result[i] = sample_dict.get(var_idx, np.nan)\n",
    "        return result\n",
    "       \n",
    "    def mpe(self, evidence) -> np.ndarray:\n",
    "        sample_dict = {}\n",
    "        for child in self.children:\n",
    "            child_mpe = child.mpe(evidence)\n",
    "            for i, var_idx in enumerate(child.scope):\n",
    "                if var_idx not in sample_dict:\n",
    "                    sample_dict[var_idx] = child_mpe[i] if len(child_mpe) > i else child_mpe\n",
    "        result = np.zeros(len(self.scope))\n",
    "        for i, var_idx in enumerate(self.scope):\n",
    "            result[i] = sample_dict.get(var_idx, np.nan)\n",
    "        return result\n",
    "\n",
    "class SumNode(SPNNode):\n",
    "    def __init__(self, children: List[SPNNode], weights: Optional[np.ndarray] = None):\n",
    "        first_scope = children[0].scope\n",
    "        for child in children[1:]:\n",
    "            if child.scope != first_scope:\n",
    "                raise ValueError(\"Sum node children must have SAME scope!\")\n",
    "               \n",
    "        super().__init__(first_scope)\n",
    "        self.children = children\n",
    "        self.n_children = len(children)\n",
    "       \n",
    "        if weights is None:\n",
    "            self.weights = np.ones(self.n_children) / self.n_children\n",
    "        else:\n",
    "            self.weights = self._normalize_weights(weights)\n",
    "           \n",
    "        self.child_log_probs = np.zeros(self.n_children)\n",
    "        self.responsibilities = np.zeros(self.n_children)\n",
    "       \n",
    "        for child in children:\n",
    "            child.parents.append(self)\n",
    "           \n",
    "    def _normalize_weights(self, weights):\n",
    "        weights = np.maximum(weights, 0)\n",
    "        total = weights.sum()\n",
    "        return weights / total if total > 1e-10 else np.ones_like(weights) / len(weights)\n",
    "       \n",
    "    def forward(self, X: np.ndarray, log_space: bool = True) -> float:\n",
    "        for i, child in enumerate(self.children):\n",
    "            self.child_log_probs[i] = child.forward(X, True)\n",
    "           \n",
    "        max_log = np.max(self.child_log_probs)\n",
    "        shifted = self.child_log_probs - max_log\n",
    "        exp_probs = np.exp(shifted)\n",
    "        weighted = np.dot(self.weights, exp_probs)\n",
    "        log_weighted = np.log(weighted + 1e-8) + max_log\n",
    "        return log_weighted if log_space else np.exp(log_weighted)\n",
    "       \n",
    "    def compute_responsibilities(self):\n",
    "        max_log = np.max(self.child_log_probs)\n",
    "        shifted = self.child_log_probs - max_log\n",
    "        exp_probs = np.exp(shifted)\n",
    "        weighted = self.weights * exp_probs\n",
    "        total = weighted.sum() + 1e-8\n",
    "        self.responsibilities = weighted / total\n",
    "        return self.responsibilities\n",
    "       \n",
    "    def backward(self, grad: float):\n",
    "        responsibilities = self.compute_responsibilities()\n",
    "        self.weights = self._normalize_weights(responsibilities)\n",
    "        for i, child in enumerate(self.children):\n",
    "            child.backward(grad * responsibilities[i])\n",
    "           \n",
    "    def collect_statistics(self, X: np.ndarray, parent_resp: float):\n",
    "        responsibilities = self.compute_responsibilities() * parent_resp\n",
    "        for i, child in enumerate(self.children):\n",
    "            if hasattr(child, 'collect_statistics'):\n",
    "                child.collect_statistics(X, responsibilities[i])\n",
    "            elif hasattr(child, 'children'):\n",
    "                child.collect_statistics(X, responsibilities[i])\n",
    "               \n",
    "    def sample(self, evidence=None) -> np.ndarray:\n",
    "        safe_weights = self._normalize_weights(self.weights)\n",
    "        child_idx = np.random.choice(self.n_children, p=safe_weights)\n",
    "        return self.children[child_idx].sample(evidence)\n",
    "       \n",
    "    def mpe(self, evidence) -> np.ndarray:\n",
    "        child_idx = np.argmax(self.weights)\n",
    "        return self.children[child_idx].mpe(evidence)\n",
    "\n",
    "# ============================================================================\n",
    "# 4. COMPLETE NUTRITION SPN WITH ALL INFERENCE CAPABILITIES\n",
    "# ============================================================================\n",
    "class NutritionSPN:\n",
    "    def __init__(self, n_nutrients: int = 6):\n",
    "        self.n_nutrients = n_nutrients\n",
    "        self.root = None\n",
    "        self.nutrient_names = ['Energy (kcal)', 'Protein (g)', 'Fiber (g)',\n",
    "                              'Iron (mg)', 'Potassium (mg)', 'Vitamin C (mg)']\n",
    "        self.node_count = 0\n",
    "        self.leaf_distributions = {}\n",
    "       \n",
    "    def build_handcrafted(self, X: np.ndarray) -> SumNode:\n",
    "        print(\"Building handcrafted SPN for nutrition...\")\n",
    "        leaves = []\n",
    "        for i in range(self.n_nutrients):\n",
    "            leaf = LeafNode([i], 'gaussian')\n",
    "            data = X[:, i]\n",
    "            valid = data[~np.isnan(data)]\n",
    "            leaf.mean = np.mean(valid) if len(valid) > 0 else 0.0\n",
    "            leaf.std = max(np.std(valid), 1e-8) if len(valid) > 0 else 1.0\n",
    "            leaves.append(leaf)\n",
    "            self.leaf_distributions[i] = {'mean': leaf.mean, 'std': leaf.std}\n",
    "       \n",
    "        product1 = ProductNode(leaves.copy())\n",
    "        product2 = ProductNode([\n",
    "            ProductNode([leaves[0], leaves[1]]),\n",
    "            ProductNode([leaves[2], leaves[3]]),\n",
    "            ProductNode([leaves[4], leaves[5]])\n",
    "        ]) if self.n_nutrients >= 6 else product1\n",
    "       \n",
    "        root = SumNode([product1, product2], weights=np.array([0.6, 0.4]))\n",
    "        self.root = root\n",
    "        self._count_nodes()\n",
    "        print(f\"Built SPN with {self.node_count} nodes\")\n",
    "        return root\n",
    "       \n",
    "    def learn_from_data(self, X: np.ndarray, **kwargs) -> SumNode:\n",
    "        print(\"Learning SPN structure...\")\n",
    "        self.root = SPNBuilder.learn_spn(X, **kwargs)\n",
    "        self._count_nodes()\n",
    "        print(f\"Learned SPN has {self.node_count} nodes\")\n",
    "       \n",
    "        trainer = SPNTrainer(self.root)\n",
    "        self.root = trainer.train(X, epochs=10, verbose=True)\n",
    "        self._collect_leaf_distributions()\n",
    "        return self.root\n",
    "       \n",
    "    def _count_nodes(self):\n",
    "        self.node_count = 0\n",
    "        if self.root:\n",
    "            self._recursive_count(self.root)\n",
    "           \n",
    "    def _recursive_count(self, node):\n",
    "        self.node_count += 1\n",
    "        if hasattr(node, 'children'):\n",
    "            for child in node.children:\n",
    "                self._recursive_count(child)\n",
    "               \n",
    "    def _collect_leaf_distributions(self):\n",
    "        if not self.root:\n",
    "            return\n",
    "        stack = [self.root]\n",
    "        while stack:\n",
    "            node = stack.pop()\n",
    "            if isinstance(node, LeafNode):\n",
    "                self.leaf_distributions[node.var_idx] = {'mean': node.mean, 'std': node.std}\n",
    "            if hasattr(node, 'children'):\n",
    "                stack.extend(node.children)\n",
    "   \n",
    "    def log_likelihood(self, X: np.ndarray) -> float:\n",
    "        if not self.root:\n",
    "            raise ValueError(\"SPN not trained\")\n",
    "        return self.root.forward(X, log_space=True)\n",
    "       \n",
    "    def probability(self, X: np.ndarray) -> float:\n",
    "        return np.exp(self.log_likelihood(X))\n",
    "       \n",
    "    def sample(self, n_samples: int = 1, evidence=None) -> np.ndarray:\n",
    "        if not self.root:\n",
    "            raise ValueError(\"SPN not trained\")\n",
    "        samples = []\n",
    "        for _ in range(n_samples):\n",
    "            samples.append(self.root.sample(evidence))\n",
    "        return np.array(samples)\n",
    "\n",
    "# ============================================================================\n",
    "# 5. VEGETABLE RECOMMENDER WITH PROFESSIONAL SPN + REAL PRICES\n",
    "# ============================================================================\n",
    "class ProfessionalVegetableRecommender:\n",
    "    def __init__(self):\n",
    "        self.spn = None\n",
    "        self.vegetable_data = None\n",
    "        self.nutrient_names = ['Energy (kcal)', 'Protein (g)', 'Fiber (g)',\n",
    "                              'Iron (mg)', 'Potassium (mg)', 'Vitamin C (mg)']\n",
    "       \n",
    "    def load_and_prepare_data(self, veg_csv_path: str) -> np.ndarray:\n",
    "        veggies = pd.read_csv(veg_csv_path)\n",
    "        nutrient_cols = ['Energ_Kcal', 'Protein_(g)', 'Fiber_TD_(g)',\n",
    "                        'Iron_(mg)', 'Potassium_(mg)', 'Vit_C_(mg)']\n",
    "        available = [c for c in nutrient_cols if c in veggies.columns]\n",
    "        \n",
    "        veg_clean = veggies[['Shrt_Desc'] + available].copy()\n",
    "        for col in available:\n",
    "            veg_clean[col] = pd.to_numeric(veg_clean[col], errors='coerce').fillna(0)\n",
    "            \n",
    "        self.vegetable_data = veg_clean\n",
    "        \n",
    "        nutrient_values = veg_clean[available].values\n",
    "        means = np.nanmean(nutrient_values, axis=0)\n",
    "        stds = np.nanstd(nutrient_values, axis=0) + 1e-8\n",
    "        normalized = (nutrient_values - means) / stds\n",
    "        \n",
    "        print(f\"Loaded {len(veg_clean)} vegetables with {len(available)} nutrients\")\n",
    "        return normalized\n",
    "       \n",
    "    def train_spn(self, X: np.ndarray, method: str = 'handcrafted'):\n",
    "        self.spn = NutritionSPN(n_nutrients=X.shape[1])\n",
    "        \n",
    "        if method == 'handcrafted':\n",
    "            print(\"Training handcrafted SPN...\")\n",
    "            self.spn.build_handcrafted(X)\n",
    "        else:\n",
    "            print(\"Training learned SPN...\")\n",
    "            self.spn.learn_from_data(X)\n",
    "       \n",
    "    def recommend(self, user_profile: Dict[str, float], n_recommendations: int = 5):\n",
    "        if self.spn is None or self.vegetable_data is None:\n",
    "            raise ValueError(\"SPN not trained or data not loaded\")\n",
    "       \n",
    "        evidence = {}\n",
    "        for nutrient, value in user_profile.items():\n",
    "            if nutrient in self.nutrient_names:\n",
    "                idx = self.nutrient_names.index(nutrient)\n",
    "                evidence[idx] = value\n",
    "       \n",
    "        nutrient_values = self.vegetable_data.iloc[:, 1:].values\n",
    "        veg_names = self.vegetable_data['Shrt_Desc'].values\n",
    "       \n",
    "        recommendations = []\n",
    "        for i, veg_nutrients in enumerate(nutrient_values):\n",
    "            x = veg_nutrients.copy()\n",
    "            for var_idx, val in evidence.items():\n",
    "                x[var_idx] = val\n",
    "               \n",
    "            log_prob = self.spn.log_likelihood(x)\n",
    "            prob = np.exp(log_prob)\n",
    "            \n",
    "            # Get real price\n",
    "            veg_name = veg_names[i]\n",
    "            real_price = get_real_price(veg_name, datetime.now().month, datetime.now().year)\n",
    "            \n",
    "            recommendations.append({\n",
    "                'vegetable': veg_name,\n",
    "                'probability': float(prob),\n",
    "                'estimated_price_per_unit': float(real_price),\n",
    "                'nutrients': {self.nutrient_names[j]: float(veg_nutrients[j]) for j in range(len(veg_nutrients))}\n",
    "            })\n",
    "       \n",
    "        recommendations.sort(key=lambda x: x['probability'], reverse=True)\n",
    "        return recommendations[:n_recommendations]\n",
    "       \n",
    "    def explain_recommendation(self, vegetable_name: str) -> Dict:\n",
    "        if self.spn is None or self.vegetable_data is None:\n",
    "            raise ValueError(\"SPN not trained or data not loaded\")\n",
    "       \n",
    "        veg_row = self.vegetable_data[self.vegetable_data['Shrt_Desc'] == vegetable_name]\n",
    "        if veg_row.empty:\n",
    "            return {\"error\": \"Vegetable not found\"}\n",
    "       \n",
    "        nutrients = veg_row.iloc[0, 1:].values\n",
    "        log_prob = self.spn.log_likelihood(nutrients)\n",
    "        prob = np.exp(log_prob)\n",
    "        \n",
    "        real_price = get_real_price(vegetable_name, datetime.now().month, datetime.now().year)\n",
    "        \n",
    "        explanation = {\n",
    "            'vegetable': vegetable_name,\n",
    "            'log_likelihood': float(log_prob),\n",
    "            'probability': float(prob),\n",
    "            'estimated_price_per_unit': float(real_price),\n",
    "            'spn_confidence': float(prob)\n",
    "        }\n",
    "       \n",
    "        return explanation\n",
    "\n",
    "# ============================================================================\n",
    "# DEMONSTRATION & EXECUTION\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PROFESSIONAL SPN IMPLEMENTATION WITH REAL PRICE INTEGRATION\")\n",
    "    print(\"Using Dambulla wholesale & Colombo market historical data\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "   \n",
    "    recommender = ProfessionalVegetableRecommender()\n",
    "   \n",
    "    # Load and train\n",
    "    print(\"1. LOADING AND PREPARING DATA\")\n",
    "    X = recommender.load_and_prepare_data('vegetables_USDA.csv')\n",
    "    recommender.train_spn(X, method='handcrafted')\n",
    "   \n",
    "    # Example user profile\n",
    "    print(\"\\n2. GENERATING RECOMMENDATIONS\")\n",
    "    user_profile = {\n",
    "        'Energy (kcal)': 80.0,\n",
    "        'Protein (g)': 2.5,\n",
    "        'Fiber (g)': 3.5,\n",
    "        'Iron (mg)': 1.8,\n",
    "        'Potassium (mg)': 350.0,\n",
    "        'Vitamin C (mg)': 40.0\n",
    "    }\n",
    "   \n",
    "    recommendations = recommender.recommend(user_profile, n_recommendations=3)\n",
    "   \n",
    "    print(f\"User Profile: {user_profile}\")\n",
    "    print(\"\\nTop Recommendations (with real prices):\")\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"{i}. {rec['vegetable']}\")\n",
    "        print(f\"   Probability: {rec['probability']:.4f}\")\n",
    "        print(f\"   Est. Price per unit: LKR {rec['estimated_price_per_unit']:.2f}\")\n",
    "   \n",
    "    # Explain top recommendation\n",
    "    if recommendations:\n",
    "        print(\"\\n3. SPN EXPLANATION FOR TOP RECOMMENDATION\")\n",
    "        explanation = recommender.explain_recommendation(recommendations[0]['vegetable'])\n",
    "        print(f\"Vegetable: {explanation['vegetable']}\")\n",
    "        print(f\"SPN Probability: {explanation['probability']:.4f}\")\n",
    "        print(f\"Estimated Price: LKR {explanation['estimated_price_per_unit']:.2f}\")\n",
    "        print(f\"SPN Confidence: {explanation['spn_confidence']:.4f}\")\n",
    "   \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SPN DEMO COMPLETE – REAL PRICES INTEGRATED\")\n",
    "    print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
