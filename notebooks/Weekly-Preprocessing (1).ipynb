{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO2Tn29joK0B28LH+6tj+y2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tGXTjFh7pJ3c","executionInfo":{"status":"ok","timestamp":1771558307294,"user_tz":-330,"elapsed":8911,"user":{"displayName":"Lasani Layathma","userId":"18358751647885209929"}},"outputId":"b5d4a380-6bd6-4e35-9fd3-5a2dda8c29eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Cloning into 'DSGP_Group_38'...\n","remote: Enumerating objects: 785, done.\u001b[K\n","remote: Counting objects: 100% (242/242), done.\u001b[K\n","remote: Compressing objects: 100% (193/193), done.\u001b[K\n","remote: Total 785 (delta 166), reused 44 (delta 44), pack-reused 543 (from 1)\u001b[K\n","Receiving objects: 100% (785/785), 44.72 MiB | 7.88 MiB/s, done.\n","Resolving deltas: 100% (302/302), done.\n","/content/DSGP_Group_38\n"]}],"source":["%cd /content\n","!git clone https://github.com/Amika1118/DSGP_Group_38.git\n","%cd DSGP_Group_38"]},{"cell_type":"code","source":["!git checkout Market-Price-Prediction"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ON-oOV8DpWjF","executionInfo":{"status":"ok","timestamp":1771558310750,"user_tz":-330,"elapsed":131,"user":{"displayName":"Lasani Layathma","userId":"18358751647885209929"}},"outputId":"a3faad96-ba80-4ccc-ebf4-06a8ae031941"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Branch 'Market-Price-Prediction' set up to track remote branch 'Market-Price-Prediction' from 'origin'.\n","Switched to a new branch 'Market-Price-Prediction'\n"]}]},{"cell_type":"code","source":["!git config --global user.name \"Lasani Layathma\"\n","!git config --global user.email \"lasani.20241357@iit.ac.lk\""],"metadata":{"id":"MZo6bp_WpZAf","executionInfo":{"status":"ok","timestamp":1771558313192,"user_tz":-330,"elapsed":228,"user":{"displayName":"Lasani Layathma","userId":"18358751647885209929"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from getpass import getpass\n","token = getpass(\"Enter GitHub token: \")\n","!git remote set-url origin https://{token}@github.com/Amika1118/DSGP_Group_38.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j9Gvh5XapZpS","executionInfo":{"status":"ok","timestamp":1771558332837,"user_tz":-330,"elapsed":2018,"user":{"displayName":"Lasani Layathma","userId":"18358751647885209929"}},"outputId":"79f005cd-af3f-4f73-f4b8-7ec8e056559c"},"execution_count":4,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter GitHub token: ··········\n"]}]},{"cell_type":"code","source":["!git pull origin Market-Price-Prediction --allow-unrelated-histories"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t6exk8NgoNjd","executionInfo":{"status":"ok","timestamp":1771349553861,"user_tz":-330,"elapsed":327,"user":{"displayName":"Lasani Layathma","userId":"18358751647885209929"}},"outputId":"b04c75a2-bba9-4868-c4e8-5a9c5d0fc190"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["remote: Enumerating objects: 38, done.\u001b[K\n","remote: Counting objects:   2% (1/38)\u001b[K\rremote: Counting objects:   5% (2/38)\u001b[K\rremote: Counting objects:   7% (3/38)\u001b[K\rremote: Counting objects:  10% (4/38)\u001b[K\rremote: Counting objects:  13% (5/38)\u001b[K\rremote: Counting objects:  15% (6/38)\u001b[K\rremote: Counting objects:  18% (7/38)\u001b[K\rremote: Counting objects:  21% (8/38)\u001b[K\rremote: Counting objects:  23% (9/38)\u001b[K\rremote: Counting objects:  26% (10/38)\u001b[K\rremote: Counting objects:  28% (11/38)\u001b[K\rremote: Counting objects:  31% (12/38)\u001b[K\rremote: Counting objects:  34% (13/38)\u001b[K\rremote: Counting objects:  36% (14/38)\u001b[K\rremote: Counting objects:  39% (15/38)\u001b[K\rremote: Counting objects:  42% (16/38)\u001b[K\rremote: Counting objects:  44% (17/38)\u001b[K\rremote: Counting objects:  47% (18/38)\u001b[K\rremote: Counting objects:  50% (19/38)\u001b[K\rremote: Counting objects:  52% (20/38)\u001b[K\rremote: Counting objects:  55% (21/38)\u001b[K\rremote: Counting objects:  57% (22/38)\u001b[K\rremote: Counting objects:  60% (23/38)\u001b[K\rremote: Counting objects:  63% (24/38)\u001b[K\rremote: Counting objects:  65% (25/38)\u001b[K\rremote: Counting objects:  68% (26/38)\u001b[K\rremote: Counting objects:  71% (27/38)\u001b[K\rremote: Counting objects:  73% (28/38)\u001b[K\rremote: Counting objects:  76% (29/38)\u001b[K\rremote: Counting objects:  78% (30/38)\u001b[K\rremote: Counting objects:  81% (31/38)\u001b[K\rremote: Counting objects:  84% (32/38)\u001b[K\rremote: Counting objects:  86% (33/38)\u001b[K\rremote: Counting objects:  89% (34/38)\u001b[K\rremote: Counting objects:  92% (35/38)\u001b[K\rremote: Counting objects:  94% (36/38)\u001b[K\rremote: Counting objects:  97% (37/38)\u001b[K\rremote: Counting objects: 100% (38/38)\u001b[K\rremote: Counting objects: 100% (38/38), done.\u001b[K\n","remote: Compressing objects:   2% (1/34)\u001b[K\rremote: Compressing objects:   5% (2/34)\u001b[K\rremote: Compressing objects:   8% (3/34)\u001b[K\rremote: Compressing objects:  11% (4/34)\u001b[K\rremote: Compressing objects:  14% (5/34)\u001b[K\rremote: Compressing objects:  17% (6/34)\u001b[K\rremote: Compressing objects:  20% (7/34)\u001b[K\rremote: Compressing objects:  23% (8/34)\u001b[K\rremote: Compressing objects:  26% (9/34)\u001b[K\rremote: Compressing objects:  29% (10/34)\u001b[K\rremote: Compressing objects:  32% (11/34)\u001b[K\rremote: Compressing objects:  35% (12/34)\u001b[K\rremote: Compressing objects:  38% (13/34)\u001b[K\rremote: Compressing objects:  41% (14/34)\u001b[K\rremote: Compressing objects:  44% (15/34)\u001b[K\rremote: Compressing objects:  47% (16/34)\u001b[K\rremote: Compressing objects:  50% (17/34)\u001b[K\rremote: Compressing objects:  52% (18/34)\u001b[K\rremote: Compressing objects:  55% (19/34)\u001b[K\rremote: Compressing objects:  58% (20/34)\u001b[K\rremote: Compressing objects:  61% (21/34)\u001b[K\rremote: Compressing objects:  64% (22/34)\u001b[K\rremote: Compressing objects:  67% (23/34)\u001b[K\rremote: Compressing objects:  70% (24/34)\u001b[K\rremote: Compressing objects:  73% (25/34)\u001b[K\rremote: Compressing objects:  76% (26/34)\u001b[K\rremote: Compressing objects:  79% (27/34)\u001b[K\rremote: Compressing objects:  82% (28/34)\u001b[K\rremote: Compressing objects:  85% (29/34)\u001b[K\rremote: Compressing objects:  88% (30/34)\u001b[K\rremote: Compressing objects:  91% (31/34)\u001b[K\rremote: Compressing objects:  94% (32/34)\u001b[K\rremote: Compressing objects:  97% (33/34)\u001b[K\rremote: Compressing objects: 100% (34/34)\u001b[K\rremote: Compressing objects: 100% (34/34), done.\u001b[K\n","remote: Total 37 (delta 13), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Unpacking objects:   2% (1/37)\rUnpacking objects:   5% (2/37)\rUnpacking objects:   8% (3/37)\rUnpacking objects:  10% (4/37)\rUnpacking objects:  13% (5/37)\rUnpacking objects:  16% (6/37)\rUnpacking objects:  18% (7/37)\rUnpacking objects:  21% (8/37)\rUnpacking objects:  24% (9/37)\rUnpacking objects:  27% (10/37)\rUnpacking objects:  29% (11/37)\rUnpacking objects:  32% (12/37)\rUnpacking objects:  35% (13/37)\rUnpacking objects:  37% (14/37)\rUnpacking objects:  40% (15/37)\rUnpacking objects:  43% (16/37)\rUnpacking objects:  45% (17/37)\rUnpacking objects:  48% (18/37)\rUnpacking objects:  51% (19/37)\rUnpacking objects:  54% (20/37)\rUnpacking objects:  56% (21/37)\rUnpacking objects:  59% (22/37)\rUnpacking objects:  62% (23/37)\rUnpacking objects:  64% (24/37)\rUnpacking objects:  67% (25/37)\rUnpacking objects:  70% (26/37)\rUnpacking objects:  72% (27/37)\rUnpacking objects:  75% (28/37)\rUnpacking objects:  78% (29/37)\rUnpacking objects:  81% (30/37)\rUnpacking objects:  83% (31/37)\rUnpacking objects:  86% (32/37)\rUnpacking objects:  89% (33/37)\rUnpacking objects:  91% (34/37)\rUnpacking objects:  94% (35/37)\rUnpacking objects:  97% (36/37)\rUnpacking objects: 100% (37/37)\rUnpacking objects: 100% (37/37), 14.04 KiB | 958.00 KiB/s, done.\n","From https://github.com/Amika1118/DSGP_Group_38\n"," * branch            Market-Price-Prediction -> FETCH_HEAD\n","   a379bbe..4f36774  Market-Price-Prediction -> origin/Market-Price-Prediction\n","Updating a379bbe..4f36774\n","Fast-forward\n"," Market-Price-Prediction => Data | 0\n"," Images                          | 1 \u001b[32m+\u001b[m\n"," Models                          | 1 \u001b[32m+\u001b[m\n"," Notebooks                       | 1 \u001b[32m+\u001b[m\n"," Outputs                         | 1 \u001b[32m+\u001b[m\n"," 5 files changed, 4 insertions(+)\n"," rename Market-Price-Prediction => Data (100%)\n"," create mode 100644 Images\n"," create mode 100644 Models\n"," create mode 100644 Notebooks\n"," create mode 100644 Outputs\n"]}]},{"cell_type":"code","source":["# Install required libraries\n","!pip install pandas openpyxl\n","\n","import pandas as pd\n","import numpy as np\n","from datetime import datetime, timedelta\n","import calendar\n","\n","# Upload the file directly to Colab\n","from google.colab import files\n","print(\"Please upload your 'Weekly raw.xlsx' file:\")\n","uploaded = files.upload()\n","\n","# Get the filename\n","filename = list(uploaded.keys())[0]\n","print(f\"\\n File '{filename}' uploaded successfully!\")\n","\n","# Load the Retail sheet\n","# header=2 because the actual column headers are in row 3 (0-indexed)\n","df = pd.read_excel(filename, sheet_name='Retail', header=2)\n","\n","print(f\"\\n Retail sheet loaded successfully!\")\n","print(f\"Initial shape: {df.shape}\")\n","\n","# Clean and prepare the dataframe\n","# Drop empty rows/columns\n","df = df.dropna(how='all').dropna(axis=1, how='all')\n","\n","# Rename columns to handle them properly\n","# First column should be Year, second Location, third Item, then W1, W2, etc.\n","column_names = ['Year', 'Location', 'Item'] + [f'W{i}' for i in range(1, 53)]  # W1 to W52\n","# Use only the columns we need\n","df.columns = column_names[:len(df.columns)]\n","\n","print(f\"After renaming columns: {df.shape}\")\n","\n","# Filter for Colombo only (your requirement)\n","df = df[df['Location'] == 'Colombo'].copy()\n","print(f\"\\n Filtered for Colombo: {df.shape}\")\n","\n","# List of vegetables to include\n","vegetables = ['Carrot', 'Cabbage', 'Tomatoes', 'Brinjals', 'Pumpkin', 'Bitter Gourd']\n","df = df[df['Item'].isin(vegetables)].copy()\n","print(f\" Filtered for 6 vegetables: {df.shape}\")\n","print(f\"Vegetables: {df['Item'].unique()}\")\n","\n","# Melt the dataframe - convert wide format to long format\n","print(\"\\n Converting from wide format to long format...\")\n","\n","# Get all week columns\n","week_columns = [col for col in df.columns if col.startswith('W')]\n","\n","# Melt the dataframe\n","df_melted = pd.melt(\n","    df,\n","    id_vars=['Year', 'Item'],\n","    value_vars=week_columns,\n","    var_name='Week',\n","    value_name='Price'\n",")\n","\n","print(f\"Melted shape: {df_melted.shape}\")\n","\n","# Remove rows with missing prices\n","df_melted = df_melted.dropna(subset=['Price']).copy()\n","print(f\"After removing NaN prices: {df_melted.shape}\")\n","\n","# Extract week number from 'W1', 'W2', etc.\n","df_melted['Week_Num'] = df_melted['Week'].str.extract('(\\d+)').astype(int)\n","\n","# Convert Year and Week to actual Date\n","def get_date_from_year_week(year, week_num):\n","    \"\"\"\n","    Convert year and week number to actual date (using Monday of that week)\n","    ISO week date system\n","    \"\"\"\n","    try:\n","        # Create date for Jan 4 (always in week 1)\n","        jan4 = datetime(int(year), 1, 4)\n","        # Find Monday of week 1\n","        week1_monday = jan4 - timedelta(days=jan4.weekday())\n","        # Add weeks\n","        target_date = week1_monday + timedelta(weeks=(week_num - 1))\n","        return target_date.strftime('%Y-%m-%d')\n","    except:\n","        return None\n","\n","print(\"\\n Converting Year-Week to actual dates...\")\n","df_melted['Date'] = df_melted.apply(\n","    lambda row: get_date_from_year_week(row['Year'], row['Week_Num']),\n","    axis=1\n",")\n","\n","# Remove rows where date conversion failed\n","df_melted = df_melted.dropna(subset=['Date']).copy()\n","print(f\"After date conversion: {df_melted.shape}\")\n","\n","# Create the final dataframe with just 3 columns\n","df_final = df_melted[['Date', 'Item', 'Price']].copy()\n","df_final.columns = ['Date', 'Vegetable', 'Price']\n","\n","# Clean the Price column\n","# Convert to numeric, force errors to NaN\n","df_final['Price'] = pd.to_numeric(df_final['Price'], errors='coerce')\n","df_final = df_final.dropna(subset=['Price']).copy()\n","\n","# Remove negative prices\n","df_final = df_final[df_final['Price'] > 0].copy()\n","\n","# Sort the data\n","df_final = df_final.sort_values(['Date', 'Vegetable']).reset_index(drop=True)\n","\n","print(f\"\\n Final dataset shape: {df_final.shape}\")\n","print(f\"Date range: {df_final['Date'].min()} to {df_final['Date'].max()}\")\n","print(f\"Number of unique vegetables: {df_final['Vegetable'].nunique()}\")\n","print(f\"Total records: {len(df_final)}\")\n","\n","# Basic statistics\n","print(\"\\n\")\n","print(\"BASIC STATISTICS BY VEGETABLE:\")\n","stats = df_final.groupby('Vegetable')['Price'].agg(['count', 'mean', 'std', 'min', 'max'])\n","print(stats.round(2))\n","\n","# Check for missing data by year\n","print(\"\\n\")\n","print(\"DATA COUNT BY YEAR:\")\n","df_final['Year'] = pd.to_datetime(df_final['Date']).dt.year\n","year_counts = df_final.groupby(['Year', 'Vegetable']).size().unstack()\n","print(year_counts)\n","\n","# Remove the temporary Year column\n","df_final = df_final.drop('Year', axis=1)\n","\n","# Save to CSV file\n","output_filename = 'colombo_retail_prices_3col.csv'\n","df_final.to_csv(output_filename, index=False)\n","print(f\"\\n CSV file saved as: '{output_filename}'\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"F93vzytB4qpy","executionInfo":{"status":"ok","timestamp":1771558373930,"user_tz":-330,"elapsed":31232,"user":{"displayName":"Lasani Layathma","userId":"18358751647885209929"}},"outputId":"fab5a836-0170-4bd6-9444-9aa0c1000ded"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["<>:69: SyntaxWarning: invalid escape sequence '\\d'\n","<>:69: SyntaxWarning: invalid escape sequence '\\d'\n","/tmp/ipython-input-1488627558.py:69: SyntaxWarning: invalid escape sequence '\\d'\n","  df_melted['Week_Num'] = df_melted['Week'].str.extract('(\\d+)').astype(int)\n"]},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n","Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Please upload your 'Weekly raw.xlsx' file:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-44973844-7058-4d5f-953a-c90ee87166be\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-44973844-7058-4d5f-953a-c90ee87166be\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Weekly raw.xlsx to Weekly raw.xlsx\n","\n"," File 'Weekly raw.xlsx' uploaded successfully!\n","\n"," Retail sheet loaded successfully!\n","Initial shape: (97, 55)\n","After renaming columns: (97, 55)\n","\n"," Filtered for Colombo: (96, 55)\n"," Filtered for 6 vegetables: (96, 55)\n","Vegetables: ['Carrot' 'Cabbage' 'Tomatoes' 'Brinjals' 'Pumpkin' 'Bitter Gourd']\n","\n"," Converting from wide format to long format...\n","Melted shape: (4992, 4)\n","After removing NaN prices: (4764, 4)\n","\n"," Converting Year-Week to actual dates...\n","After date conversion: (4764, 6)\n","\n"," Final dataset shape: (4764, 3)\n","Date range: 2010-01-04 to 2025-12-22\n","Number of unique vegetables: 6\n","Total records: 4764\n","\n","\n","BASIC STATISTICS BY VEGETABLE:\n","              count    mean     std    min      max\n","Vegetable                                          \n","Bitter Gourd    794  263.67  162.54  86.60   977.78\n","Brinjals        794  204.00  142.30  53.38   825.17\n","Cabbage         794  183.06  119.31  56.78   854.33\n","Carrot          794  241.04  165.96  72.89  1703.33\n","Pumpkin         794  131.70   67.49  49.66   390.74\n","Tomatoes        794  211.42  163.66  44.19  1058.52\n","\n","\n","DATA COUNT BY YEAR:\n","Vegetable  Bitter Gourd  Brinjals  Cabbage  Carrot  Pumpkin  Tomatoes\n","Year                                                                 \n","2010                 52        52       52      52       52        52\n","2011                 52        52       52      52       52        52\n","2012                 52        52       52      52       52        52\n","2013                 51        51       51      51       51        51\n","2014                 52        52       52      52       52        52\n","2015                 51        51       51      51       51        51\n","2016                 52        52       52      52       52        52\n","2017                 52        52       52      52       52        52\n","2018                 53        53       53      53       53        53\n","2019                 51        51       51      51       51        51\n","2020                 24        24       24      24       24        24\n","2021                 44        44       44      44       44        44\n","2022                 52        52       52      52       52        52\n","2023                 52        52       52      52       52        52\n","2024                 53        53       53      53       53        53\n","2025                 51        51       51      51       51        51\n","\n"," CSV file saved as: 'colombo_retail_prices_3col.csv'\n"]}]},{"cell_type":"code","source":["# Install and import required libraries\n","!pip install pandas numpy\n","\n","import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","from google.colab import files\n","\n","# Upload your CSV file\n","print(\"Please upload your 'weekly structured.csv' file:\")\n","uploaded = files.upload()\n","\n","# Get filename\n","filename = list(uploaded.keys())[0]\n","print(f\"\\n File '{filename}' uploaded successfully!\")\n","\n","# Load the CSV\n","df = pd.read_csv(filename)\n","df['Date'] = pd.to_datetime(df['Date'])\n","\n","print(f\"\\n Original dataset shape: {df.shape}\")\n","print(f\"Date range: {df['Date'].min()} to {df['Date'].max()}\")\n","print(f\"Vegetables: {df['Vegetable'].unique()}\")\n","print(\"\\nFirst 5 rows:\")\n","print(df.head())\n","\n","# Sort data chronologically\n","df = df.sort_values(['Vegetable', 'Date']).reset_index(drop=True)\n","print(\"\\n Data sorted by Vegetable and Date\")\n","\n","# Create a function to add all features for each vegetable\n","def add_all_features(df):\n","    \"\"\"Add all preprocessing columns to the dataframe\"\"\"\n","\n","    # Make a copy to avoid warnings\n","    df = df.copy()\n","\n","    # 1. TIME FEATURES (From Date column)\n","    print(\"\\n Adding TIME FEATURES...\")\n","    df['Year'] = df['Date'].dt.year\n","    df['Month'] = df['Date'].dt.month\n","    df['Week_of_Year'] = df['Date'].dt.isocalendar().week\n","    df['Quarter'] = df['Date'].dt.quarter\n","\n","    # 2. ONE-HOT ENCODING (Vegetable indicators)\n","    print(\" Adding ONE-HOT ENCODING...\")\n","    vegetables = ['Bitter Gourd', 'Brinjals', 'Cabbage', 'Carrot', 'Pumpkin', 'Tomatoes']\n","    for veg in vegetables:\n","        col_name = f'Is_{veg.replace(\" \", \"_\")}'\n","        df[col_name] = (df['Vegetable'] == veg).astype(int)\n","\n","    # 3. LAG FEATURES (Past prices)\n","    print(\" Adding LAG FEATURES...\")\n","\n","    # Sort to ensure correct order for lag calculation\n","    df = df.sort_values(['Vegetable', 'Date']).reset_index(drop=True)\n","\n","    # Group by vegetable to calculate lags correctly\n","    for veg in df['Vegetable'].unique():\n","        mask = df['Vegetable'] == veg\n","\n","        # Price lags\n","        df.loc[mask, 'Price_Lag_1'] = df.loc[mask, 'Price'].shift(1)\n","        df.loc[mask, 'Price_Lag_2'] = df.loc[mask, 'Price'].shift(2)\n","        df.loc[mask, 'Price_Lag_3'] = df.loc[mask, 'Price'].shift(3)\n","        df.loc[mask, 'Price_Lag_4'] = df.loc[mask, 'Price'].shift(4)\n","        df.loc[mask, 'Price_Lag_8'] = df.loc[mask, 'Price'].shift(8)\n","        df.loc[mask, 'Price_Lag_12'] = df.loc[mask, 'Price'].shift(12)\n","        df.loc[mask, 'Price_Lag_52'] = df.loc[mask, 'Price'].shift(52)\n","\n","    # 4. ROLLING STATISTICS (Trends over time)\n","    print(\" Adding ROLLING STATISTICS...\")\n","\n","    for veg in df['Vegetable'].unique():\n","        mask = df['Vegetable'] == veg\n","\n","        # Rolling means\n","        df.loc[mask, 'Rolling_Mean_4'] = df.loc[mask, 'Price'].rolling(window=4, min_periods=1).mean()\n","        df.loc[mask, 'Rolling_Mean_8'] = df.loc[mask, 'Price'].rolling(window=8, min_periods=1).mean()\n","        df.loc[mask, 'Rolling_Mean_12'] = df.loc[mask, 'Price'].rolling(window=12, min_periods=1).mean()\n","\n","        # Rolling min and max\n","        df.loc[mask, 'Rolling_Min_4'] = df.loc[mask, 'Price'].rolling(window=4, min_periods=1).min()\n","        df.loc[mask, 'Rolling_Max_4'] = df.loc[mask, 'Price'].rolling(window=4, min_periods=1).max()\n","\n","        # Rolling standard deviation (volatility)\n","        df.loc[mask, 'Rolling_Std_4'] = df.loc[mask, 'Price'].rolling(window=4, min_periods=1).std()\n","\n","    # 5. PRICE CHANGE FEATURES\n","    print(\" Adding PRICE CHANGE FEATURES...\")\n","\n","    for veg in df['Vegetable'].unique():\n","        mask = df['Vegetable'] == veg\n","\n","        # Price change from 1 week ago\n","        df.loc[mask, 'Price_Change_1wk'] = df.loc[mask, 'Price'] - df.loc[mask, 'Price'].shift(1)\n","\n","        # Percentage change from 1 week ago\n","        df.loc[mask, 'Price_Change_Pct_1wk'] = (df.loc[mask, 'Price'] - df.loc[mask, 'Price'].shift(1)) / df.loc[mask, 'Price'].shift(1) * 100\n","\n","        # Price change from 4 weeks ago\n","        df.loc[mask, 'Price_Change_4wk'] = df.loc[mask, 'Price'] - df.loc[mask, 'Price'].shift(4)\n","\n","    # 6. SEASONAL FEATURES (Monthly averages)\n","    print(\" Adding SEASONAL FEATURES...\")\n","\n","    # Calculate monthly average price for each vegetable\n","    monthly_avg = df.groupby(['Vegetable', 'Month'])['Price'].transform('mean')\n","    df['Month_Avg_Price'] = monthly_avg\n","\n","    # Compare current price to monthly average\n","    df['Price_vs_Month_Avg'] = df['Price'] - df['Month_Avg_Price']\n","\n","    # 7. CLEAN UP - Remove rows with NaN values (first few weeks)\n","    print(\" Cleaning up NaN values...\")\n","\n","    # For time series, we need at least Price_Lag_1 to make predictions\n","    initial_rows = len(df)\n","    df = df.dropna(subset=['Price_Lag_1']).reset_index(drop=True)\n","    removed_rows = initial_rows - len(df)\n","    print(f\"   Removed {removed_rows} rows with NaN lag values (first weeks of data)\")\n","\n","    # Fill any remaining NaN values in rolling stats with forward fill\n","    df = df.fillna(method='ffill')\n","\n","    # Fill any remaining NaN values with 0\n","    df = df.fillna(0)\n","\n","    return df\n","\n","# Apply the feature engineering function\n","print(\"\\n\")\n","print(\" STARTING FEATURE ENGINEERING...\")\n","\n","df_featured = add_all_features(df)\n","\n","print(\"\\n Feature engineering complete!\")\n","print(f\"   New dataset shape: {df_featured.shape}\")\n","print(f\"   Total columns: {len(df_featured.columns)}\")\n","\n","# Reorder columns to match your requested format\n","print(\"\\n Reordering columns...\")\n","\n","# Define the exact column order you requested\n","column_order = [\n","    'Date',\n","    'Vegetable',\n","    'Price',  # TARGET\n","    'Year',\n","    'Month',\n","    'Week_of_Year',\n","    'Quarter',\n","    'Price_Lag_1',\n","    'Price_Lag_2',\n","    'Price_Lag_3',\n","    'Price_Lag_4',\n","    'Price_Lag_8',\n","    'Price_Lag_12',\n","    'Price_Lag_52',\n","    'Rolling_Mean_4',\n","    'Rolling_Mean_8',\n","    'Rolling_Mean_12',\n","    'Rolling_Std_4',\n","    'Rolling_Min_4',\n","    'Rolling_Max_4',\n","    'Price_Change_1wk',\n","    'Price_Change_Pct_1wk',\n","    'Price_Change_4wk',\n","    'Month_Avg_Price',\n","    'Price_vs_Month_Avg',\n","    'Is_Bitter_Gourd',\n","    'Is_Brinjals',\n","    'Is_Cabbage',\n","    'Is_Carrot',\n","    'Is_Pumpkin',\n","    'Is_Tomatoes'\n","]\n","\n","# Add only columns that exist in our dataframe\n","final_columns = [col for col in column_order if col in df_featured.columns]\n","df_final = df_featured[final_columns].copy()\n","\n","print(f\" Final dataset has {len(final_columns)} columns\")\n","\n","# Display column information\n","print(\"\\n\")\n","print(\" COLUMN INFORMATION\")\n","for i, col in enumerate(df_final.columns, 1):\n","    dtype = df_final[col].dtype\n","    non_null = df_final[col].count()\n","    print(f\"{i:2d}. {col:25s} | dtype: {str(dtype):8s} | non-null: {non_null:6d}\")\n","\n","# Basic statistics of the preprocessed data\n","print(\"\\n\")\n","print(\" BASIC STATISTICS (Numerical Columns)\")\n","print(df_final.describe().round(2))\n","\n","# Check for any remaining missing values\n","print(\"\\n\")\n","print(\" MISSING VALUES CHECK\")\n","missing_values = df_final.isnull().sum()\n","if missing_values.sum() == 0:\n","    print(\" No missing values found! Dataset is clean.\")\n","else:\n","    print(missing_values[missing_values > 0])\n","\n","# Verify lag features are working correctly\n","print(\"\\n\")\n","print(\" VERIFYING LAG FEATURES (Carrot example)\")\n","carrot_sample = df_final[df_final['Is_Carrot'] == 1].head(10)\n","print(carrot_sample[['Date', 'Price', 'Price_Lag_1', 'Price_Lag_2', 'Price_Change_1wk']].to_string())\n","\n","# Save the preprocessed dataset\n","output_filename = 'weekly_preprocessed_complete.csv'\n","df_final.to_csv(output_filename, index=False)\n","print(f\"\\n Preprocessed dataset saved as: '{output_filename}'\")\n","print(f\"   File size: {len(df_final)} rows × {len(df_final.columns)} columns\")\n","'''\n"," FEATURE SUMMARY:\n","   • Time Features: Year, Month, Week_of_Year, Quarter\n","   • Lag Features: Price_Lag_1,2,3,4,8,12,52\n","   • Rolling Stats: Mean_4,8,12, Std_4, Min_4, Max_4\n","   • Price Changes: 1wk, 4wk, Pct_1wk\n","   • Seasonal: Month_Avg_Price, Price_vs_Month_Avg\n","   • Encoding: 6 one-hot columns for vegetables'''\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"qN-RA79n5Vi9","executionInfo":{"status":"ok","timestamp":1771558404171,"user_tz":-330,"elapsed":25428,"user":{"displayName":"Lasani Layathma","userId":"18358751647885209929"}},"outputId":"a8e42dbb-1b8b-4d5a-ca17-917d3dd733e4"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Please upload your 'weekly structured.csv' file:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-0d461681-30a7-4df1-b883-c8cebcc342e9\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-0d461681-30a7-4df1-b883-c8cebcc342e9\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving weekly structured.csv to weekly structured.csv\n","\n"," File 'weekly structured.csv' uploaded successfully!\n","\n"," Original dataset shape: (4764, 3)\n","Date range: 2010-01-04 00:00:00 to 2025-12-22 00:00:00\n","Vegetables: ['Bitter Gourd' 'Brinjals' 'Cabbage' 'Carrot' 'Pumpkin' 'Tomatoes']\n","\n","First 5 rows:\n","        Date     Vegetable   Price\n","0 2010-01-04  Bitter Gourd  114.12\n","1 2010-01-04      Brinjals  113.17\n","2 2010-01-04       Cabbage   93.78\n","3 2010-01-04        Carrot  129.76\n","4 2010-01-04       Pumpkin   60.00\n","\n"," Data sorted by Vegetable and Date\n","\n","\n"," STARTING FEATURE ENGINEERING...\n","\n"," Adding TIME FEATURES...\n"," Adding ONE-HOT ENCODING...\n"," Adding LAG FEATURES...\n"," Adding ROLLING STATISTICS...\n"," Adding PRICE CHANGE FEATURES...\n"," Adding SEASONAL FEATURES...\n"," Cleaning up NaN values...\n","   Removed 6 rows with NaN lag values (first weeks of data)\n","\n"," Feature engineering complete!\n","   New dataset shape: (4758, 31)\n","   Total columns: 31\n","\n"," Reordering columns...\n"," Final dataset has 31 columns\n","\n","\n"," COLUMN INFORMATION\n"," 1. Date                      | dtype: datetime64[ns] | non-null:   4758\n"," 2. Vegetable                 | dtype: object   | non-null:   4758\n"," 3. Price                     | dtype: float64  | non-null:   4758\n"," 4. Year                      | dtype: int32    | non-null:   4758\n"," 5. Month                     | dtype: int32    | non-null:   4758\n"," 6. Week_of_Year              | dtype: UInt32   | non-null:   4758\n"," 7. Quarter                   | dtype: int32    | non-null:   4758\n"," 8. Price_Lag_1               | dtype: float64  | non-null:   4758\n"," 9. Price_Lag_2               | dtype: float64  | non-null:   4758\n","10. Price_Lag_3               | dtype: float64  | non-null:   4758\n","11. Price_Lag_4               | dtype: float64  | non-null:   4758\n","12. Price_Lag_8               | dtype: float64  | non-null:   4758\n","13. Price_Lag_12              | dtype: float64  | non-null:   4758\n","14. Price_Lag_52              | dtype: float64  | non-null:   4758\n","15. Rolling_Mean_4            | dtype: float64  | non-null:   4758\n","16. Rolling_Mean_8            | dtype: float64  | non-null:   4758\n","17. Rolling_Mean_12           | dtype: float64  | non-null:   4758\n","18. Rolling_Std_4             | dtype: float64  | non-null:   4758\n","19. Rolling_Min_4             | dtype: float64  | non-null:   4758\n","20. Rolling_Max_4             | dtype: float64  | non-null:   4758\n","21. Price_Change_1wk          | dtype: float64  | non-null:   4758\n","22. Price_Change_Pct_1wk      | dtype: float64  | non-null:   4758\n","23. Price_Change_4wk          | dtype: float64  | non-null:   4758\n","24. Month_Avg_Price           | dtype: float64  | non-null:   4758\n","25. Price_vs_Month_Avg        | dtype: float64  | non-null:   4758\n","26. Is_Bitter_Gourd           | dtype: int64    | non-null:   4758\n","27. Is_Brinjals               | dtype: int64    | non-null:   4758\n","28. Is_Cabbage                | dtype: int64    | non-null:   4758\n","29. Is_Carrot                 | dtype: int64    | non-null:   4758\n","30. Is_Pumpkin                | dtype: int64    | non-null:   4758\n","31. Is_Tomatoes               | dtype: int64    | non-null:   4758\n","\n","\n"," BASIC STATISTICS (Numerical Columns)\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1352587133.py:124: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  df = df.fillna(method='ffill')\n"]},{"output_type":"stream","name":"stdout","text":["                                Date    Price     Year    Month  Week_of_Year  \\\n","count                           4758  4758.00  4758.00  4758.00        4758.0   \n","mean   2017-11-21 14:08:01.210592512   205.94  2017.39     6.51         26.51   \n","min              2010-01-11 00:00:00    44.19  2010.00     1.00           1.0   \n","25%              2013-11-11 00:00:00   106.36  2013.00     4.00          13.0   \n","50%              2017-09-04 00:00:00   157.03  2017.00     7.00          27.0   \n","75%              2022-03-07 00:00:00   255.71  2022.00     9.00          39.0   \n","max              2025-12-22 00:00:00  1703.33  2025.00    12.00          52.0   \n","std                              NaN   147.41     4.67     3.44         15.01   \n","\n","       Quarter  Price_Lag_1  Price_Lag_2  Price_Lag_3  Price_Lag_4  ...  \\\n","count  4758.00      4758.00      4758.00      4758.00      4758.00  ...   \n","mean      2.51       205.35       205.17       205.00       204.95  ...   \n","min       1.00        44.19         0.00         0.00         0.00  ...   \n","25%       2.00       106.31       106.30       106.29       106.26  ...   \n","50%       3.00       156.61       156.55       156.50       156.43  ...   \n","75%       3.00       255.55       255.34       255.55       255.34  ...   \n","max       4.00      1703.33      1703.33      1703.33      1703.33  ...   \n","std       1.11       146.60       146.39       145.94       146.06  ...   \n","\n","       Price_Change_Pct_1wk  Price_Change_4wk  Month_Avg_Price  \\\n","count               4758.00           4758.00          4758.00   \n","mean                   1.01              2.28           205.78   \n","min                  -50.08           -981.48           116.63   \n","25%                   -5.86            -23.83           166.66   \n","50%                   -0.31              0.31           203.25   \n","75%                    6.06             28.56           247.09   \n","max                  130.70           1170.00           354.75   \n","std                   13.11             86.12            53.08   \n","\n","       Price_vs_Month_Avg  Is_Bitter_Gourd  Is_Brinjals  Is_Cabbage  \\\n","count             4758.00          4758.00      4758.00     4758.00   \n","mean                 0.16             0.17         0.17        0.17   \n","min               -242.48             0.00         0.00        0.00   \n","25%                -87.94             0.00         0.00        0.00   \n","50%                -40.64             0.00         0.00        0.00   \n","75%                 50.78             0.00         0.00        0.00   \n","max               1391.38             1.00         1.00        1.00   \n","std                137.47             0.37         0.37        0.37   \n","\n","       Is_Carrot  Is_Pumpkin  Is_Tomatoes  \n","count    4758.00     4758.00      4758.00  \n","mean        0.17        0.17         0.17  \n","min         0.00        0.00         0.00  \n","25%         0.00        0.00         0.00  \n","50%         0.00        0.00         0.00  \n","75%         0.00        0.00         0.00  \n","max         1.00        1.00         1.00  \n","std         0.37        0.37         0.37  \n","\n","[8 rows x 30 columns]\n","\n","\n"," MISSING VALUES CHECK\n"," No missing values found! Dataset is clean.\n","\n","\n"," VERIFYING LAG FEATURES (Carrot example)\n","           Date   Price  Price_Lag_1  Price_Lag_2  Price_Change_1wk\n","2379 2010-01-11  134.88       129.76   372.727273              5.12\n","2380 2010-01-18  139.05       134.88   129.760000              4.17\n","2381 2010-01-25  131.46       139.05   134.880000             -7.59\n","2382 2010-02-01  117.73       131.46   139.050000            -13.73\n","2383 2010-02-08  101.59       117.73   131.460000            -16.14\n","2384 2010-02-15   95.56       101.59   117.730000             -6.03\n","2385 2010-02-22   96.28        95.56   101.590000              0.72\n","2386 2010-03-01  110.45        96.28    95.560000             14.17\n","2387 2010-03-08   94.55       110.45    96.280000            -15.90\n","2388 2010-03-15   90.23        94.55   110.450000             -4.32\n","\n"," Preprocessed dataset saved as: 'weekly_preprocessed_complete.csv'\n","   File size: 4758 rows × 31 columns\n"]},{"output_type":"execute_result","data":{"text/plain":["'\\n FEATURE SUMMARY:\\n   • Time Features: Year, Month, Week_of_Year, Quarter\\n   • Lag Features: Price_Lag_1,2,3,4,8,12,52\\n   • Rolling Stats: Mean_4,8,12, Std_4, Min_4, Max_4\\n   • Price Changes: 1wk, 4wk, Pct_1wk\\n   • Seasonal: Month_Avg_Price, Price_vs_Month_Avg\\n   • Encoding: 6 one-hot columns for vegetables'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Install and import required libraries\n","!pip install pandas numpy\n","\n","import pandas as pd\n","import numpy as np\n","from datetime import datetime, timedelta\n","from google.colab import files\n","\n","# Upload fuel prices CSV file\n","print(\"Please upload your 'fuel_prices (1).csv' file:\")\n","uploaded = files.upload()\n","\n","# Get filename\n","filename = list(uploaded.keys())[0]\n","print(f\"\\n File '{filename}' uploaded successfully!\")\n","\n","# Load the CSV\n","df_fuel = pd.read_csv(filename)\n","\n","print(f\"\\n Original dataset shape: {df_fuel.shape}\")\n","print(f\"Date range in original: {pd.to_datetime(df_fuel['date']).min()} to {pd.to_datetime(df_fuel['date']).max()}\")\n","\n","# Clean and prepare the fuel data\n","print(\"\\n\")\n","print(\" PROCESSING FUEL PRICE DATA (2010-2025 ONLY)...\")\n","\n","# Make a copy to work with\n","df = df_fuel.copy()\n","\n","# Convert date column to datetime\n","df['date'] = pd.to_datetime(df['date'])\n","\n","# Keep only relevant columns and rename\n","df = df[['date', 'auto_diesel']].copy()\n","df.columns = ['Date', 'Fuel_Price']\n","\n","# Sort by date\n","df = df.sort_values('Date').reset_index(drop=True)\n","\n","# FILTER FOR 2010-2025 ONLY\n","start_date = '2010-01-01'\n","end_date = '2025-12-31'\n","\n","df_filtered = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)].copy()\n","\n","print(f\"\\n Filtered to 2010-2025:\")\n","print(f\"   Original rows: {len(df)}\")\n","print(f\"   Filtered rows: {len(df_filtered)}\")\n","print(f\"   Date range: {df_filtered['Date'].min()} to {df_filtered['Date'].max()}\")\n","print(f\"   Fuel price range: Rs.{df_filtered['Fuel_Price'].min()} to Rs.{df_filtered['Fuel_Price'].max()}\")\n","\n","# Create complete weekly date range for 2010-2025\n","print(\"\\n Creating weekly date range (2010-2025)...\")\n","\n","# Create weekly dates from 2010 to 2025 (every Monday)\n","weekly_dates = pd.date_range(start='2010-01-04', end='2025-12-29', freq='W-MON')\n","weekly_df = pd.DataFrame({'Date': weekly_dates})\n","\n","print(f\"   Created {len(weekly_df)} weekly dates from {weekly_df['Date'].min()} to {weekly_df['Date'].max()}\")\n","\n","# Merge and interpolate fuel prices to weekly frequency\n","print(\"\\n Interpolating fuel prices to weekly frequency...\")\n","\n","# Merge weekly dates with actual fuel price changes\n","df_weekly = pd.merge(weekly_df, df_filtered, on='Date', how='left')\n","\n","# Forward fill to get the most recent fuel price for each week\n","# (Fuel prices remain constant until the next price change)\n","df_weekly['Fuel_Price'] = df_weekly['Fuel_Price'].fillna(method='ffill')\n","\n","# Also backward fill for any missing at the beginning\n","df_weekly['Fuel_Price'] = df_weekly['Fuel_Price'].fillna(method='bfill')\n","\n","print(f\" Weekly fuel data: {len(df_weekly)} rows\")\n","print(f\"   Missing values after interpolation: {df_weekly['Fuel_Price'].isna().sum()}\")\n","\n","# Format Date as YYYY-MM-DD string\n","df_weekly['Date'] = df_weekly['Date'].dt.strftime('%Y-%m-%d')\n","\n","# Display statistics for 2010-2025 period\n","print(\"\\n\")\n","print(\" FUEL PRICE STATISTICS (2010-2025)\")\n","print(f\"Total weeks: {len(df_weekly)}\")\n","print(f\"Date range: {df_weekly['Date'].min()} to {df_weekly['Date'].max()}\")\n","print(f\"Min price: Rs.{df_weekly['Fuel_Price'].min():.2f}\")\n","print(f\"Max price: Rs.{df_weekly['Fuel_Price'].max():.2f}\")\n","print(f\"Mean price: Rs.{df_weekly['Fuel_Price'].mean():.2f}\")\n","print(f\"Median price: Rs.{df_weekly['Fuel_Price'].median():.2f}\")\n","print(f\"Std deviation: Rs.{df_weekly['Fuel_Price'].std():.2f}\")\n","\n","# Count price changes in 2010-2025\n","price_changes = df_weekly['Fuel_Price'].diff().fillna(0) != 0\n","n_changes = price_changes.sum()\n","print(f\"\\nNumber of fuel price changes (2010-2025): {n_changes}\")\n","print(f\"Average days between changes: {len(df_weekly) / n_changes * 7:.1f} days\")\n","\n","# Show fuel price at start and end of period\n","print(f\"\\n Fuel price on {df_weekly['Date'].iloc[0]}: Rs.{df_weekly['Fuel_Price'].iloc[0]:.2f}\")\n","print(f\" Fuel price on {df_weekly['Date'].iloc[-1]}: Rs.{df_weekly['Fuel_Price'].iloc[-1]:.2f}\")\n","print(f\" Total increase: Rs.{df_weekly['Fuel_Price'].iloc[-1] - df_weekly['Fuel_Price'].iloc[0]:.2f}\")\n","\n","# Save the processed fuel price data (2010-2025 only)\n","output_filename = 'weekly_fuel_prices_2010_2025.csv'\n","df_weekly.to_csv(output_filename, index=False)\n","print(f\"\\n Weekly fuel prices (2010-2025) saved as: '{output_filename}'\")\n","print(f\"   File: {len(df_weekly)} rows × 2 columns\")\n","\n","# Also save the original filtered price changes (for reference)\n","print(\"\\n Saving original fuel price change dates (2010-2025)...\")\n","df_original_filtered = df_filtered.copy()\n","df_original_filtered['Date'] = df_original_filtered['Date'].dt.strftime('%Y-%m-%d')\n","original_filename = 'fuel_price_changes_2010_2025.csv'\n","df_original_filtered.to_csv(original_filename, index=False)\n","print(f\" Original price changes (2010-2025) saved as: '{original_filename}'\")\n","print(f\"   Records: {len(df_original_filtered)} price changes\")\n","files.download(original_filename)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"nVVuvon7gsI2","executionInfo":{"status":"ok","timestamp":1771558443060,"user_tz":-330,"elapsed":37560,"user":{"displayName":"Lasani Layathma","userId":"18358751647885209929"}},"outputId":"f95d7338-b2b7-4364-a4f9-536f5a5c4aa6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Please upload your 'fuel_prices (1).csv' file:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-88d12c77-896e-4b39-8944-b2329dc0c456\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-88d12c77-896e-4b39-8944-b2329dc0c456\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving fuel_prices (1).csv to fuel_prices (1).csv\n","\n"," File 'fuel_prices (1).csv' uploaded successfully!\n","\n"," Original dataset shape: (170, 16)\n","Date range in original: 1990-03-01 00:00:00 to 2025-11-01 00:00:00\n","\n","\n"," PROCESSING FUEL PRICE DATA (2010-2025 ONLY)...\n","\n"," Filtered to 2010-2025:\n","   Original rows: 170\n","   Filtered rows: 91\n","   Date range: 2010-09-01 00:00:00 to 2025-11-01 00:00:00\n","   Fuel price range: Rs.73.0 to Rs.460.0\n","\n"," Creating weekly date range (2010-2025)...\n","   Created 835 weekly dates from 2010-01-04 00:00:00 to 2025-12-29 00:00:00\n","\n"," Interpolating fuel prices to weekly frequency...\n"," Weekly fuel data: 835 rows\n","   Missing values after interpolation: 0\n","\n","\n"," FUEL PRICE STATISTICS (2010-2025)\n","Total weeks: 835\n","Date range: 2010-01-04 to 2025-12-29\n","Min price: Rs.121.00\n","Max price: Rs.430.00\n","Mean price: Rs.170.61\n","Median price: Rs.121.00\n","Std deviation: Rs.93.27\n","\n","Number of fuel price changes (2010-2025): 11\n","Average days between changes: 531.4 days\n","\n"," Fuel price on 2010-01-04: Rs.121.00\n"," Fuel price on 2025-12-29: Rs.283.00\n"," Total increase: Rs.162.00\n","\n"," Weekly fuel prices (2010-2025) saved as: 'weekly_fuel_prices_2010_2025.csv'\n","   File: 835 rows × 2 columns\n","\n"," Saving original fuel price change dates (2010-2025)...\n"," Original price changes (2010-2025) saved as: 'fuel_price_changes_2010_2025.csv'\n","   Records: 91 price changes\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2442955923.py:69: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  df_weekly['Fuel_Price'] = df_weekly['Fuel_Price'].fillna(method='ffill')\n","/tmp/ipython-input-2442955923.py:72: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  df_weekly['Fuel_Price'] = df_weekly['Fuel_Price'].fillna(method='bfill')\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_ead5499b-ef71-4976-890d-9f3cacf5827a\", \"fuel_price_changes_2010_2025.csv\", 1556)"]},"metadata":{}}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Read both CSV files\n","fuel_df = pd.read_csv('weekly_fuel_prices_2010_2025.csv')\n","veg_df = pd.read_csv('weekly_preprocessed_complete.csv')\n","\n","# Ensure date columns are in datetime format for proper merging\n","fuel_df['Date'] = pd.to_datetime(fuel_df['Date'])\n","veg_df['Date'] = pd.to_datetime(veg_df['Date'])\n","\n","# Perform left merge to keep all vegetable data and add fuel prices\n","merged_df = pd.merge(veg_df, fuel_df[['Date', 'Fuel_Price']], on='Date', how='left')\n","\n","# Save the merged dataframe to a new CSV file\n","merged_df.to_csv('weekly_preprocessed_with_fuel.csv', index=False)\n","\n","print(f\"Original vegetable dataset rows: {len(veg_df)}\")\n","print(f\"Original fuel dataset rows: {len(fuel_df)}\")\n","print(f\"Merged dataset rows: {len(merged_df)}\")\n","print(f\"\\nColumns in merged dataset: {merged_df.columns.tolist()}\")\n","print(f\"\\nFuel price statistics:\")\n","print(merged_df['Fuel_Price'].describe())\n","print(f\"\\nMissing fuel prices: {merged_df['Fuel_Price'].isna().sum()}\")\n","\n","# Display first few rows to verify the merge\n","print(\"\\nFirst 5 rows of merged dataset:\")\n","print(merged_df[['Date', 'Vegetable', 'Price', 'Fuel_Price']].head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tub1EwTXnZCS","executionInfo":{"status":"ok","timestamp":1771558784252,"user_tz":-330,"elapsed":279,"user":{"displayName":"Lasani Layathma","userId":"18358751647885209929"}},"outputId":"20067242-aae4-4c07-a06d-d9933112e216"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Original vegetable dataset rows: 4758\n","Original fuel dataset rows: 835\n","Merged dataset rows: 4758\n","\n","Columns in merged dataset: ['Date', 'Vegetable', 'Price', 'Year', 'Month', 'Week_of_Year', 'Quarter', 'Price_Lag_1', 'Price_Lag_2', 'Price_Lag_3', 'Price_Lag_4', 'Price_Lag_8', 'Price_Lag_12', 'Price_Lag_52', 'Rolling_Mean_4', 'Rolling_Mean_8', 'Rolling_Mean_12', 'Rolling_Std_4', 'Rolling_Min_4', 'Rolling_Max_4', 'Price_Change_1wk', 'Price_Change_Pct_1wk', 'Price_Change_4wk', 'Month_Avg_Price', 'Price_vs_Month_Avg', 'Is_Bitter_Gourd', 'Is_Brinjals', 'Is_Cabbage', 'Is_Carrot', 'Is_Pumpkin', 'Is_Tomatoes', 'Fuel_Price']\n","\n","Fuel price statistics:\n","count    4758.000000\n","mean      173.036570\n","std        94.879005\n","min       121.000000\n","25%       121.000000\n","50%       121.000000\n","75%       121.000000\n","max       430.000000\n","Name: Fuel_Price, dtype: float64\n","\n","Missing fuel prices: 0\n","\n","First 5 rows of merged dataset:\n","        Date     Vegetable   Price  Fuel_Price\n","0 2010-01-11  Bitter Gourd  116.13       121.0\n","1 2010-01-18  Bitter Gourd  120.54       121.0\n","2 2010-01-25  Bitter Gourd  115.14       121.0\n","3 2010-02-01  Bitter Gourd  111.50       121.0\n","4 2010-02-08  Bitter Gourd  116.15       121.0\n"]}]}]}