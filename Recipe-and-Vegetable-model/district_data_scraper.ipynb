{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d26573b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sri Lanka District Data Scraping System\n",
      "Version 2.0 - Complete and Robust\n",
      "--------------------------------------------------\n",
      "Checking dependencies...\n",
      "✅ requests\n",
      "✅ pandas\n",
      "✅ numpy\n",
      "⚠️  beautifulsoup4 not installed (optional, some features limited)\n",
      "\n",
      "============================================================\n",
      "SRI LANKA DISTRICT DATA SCRAPING SYSTEM\n",
      "============================================================\n",
      "Start Time: 2026-01-18 22:12:11\n",
      "============================================================\n",
      "\n",
      "[1/4] SCRAPING CENSUS DATA...\n",
      "============================================================\n",
      "SCRAPING CENSUS DATA\n",
      "============================================================\n",
      "\n",
      "[1] Checking Wikipedia...\n",
      "\n",
      "[2] Checking World Bank API...\n",
      "  Found API data for 25 districts\n",
      "✓ Saved: sri_lanka_district_census.csv (25 records)\n",
      "\n",
      "[2/4] SCRAPING AGRICULTURE DATA...\n",
      "\n",
      "============================================================\n",
      "SCRAPING AGRICULTURE DATA\n",
      "============================================================\n",
      "\n",
      "[1] Checking FAO data...\n",
      "\n",
      "[2] Generating district-level agriculture data...\n",
      "  Generated 200 synthetic records\n",
      "✓ Saved: district_agriculture_data.csv (200 records)\n",
      "\n",
      "[3/4] SCRAPING MARKET INFRASTRUCTURE DATA...\n",
      "\n",
      "============================================================\n",
      "SCRAPING MARKET INFRASTRUCTURE DATA\n",
      "============================================================\n",
      "\n",
      "[1] Generating market infrastructure data...\n",
      "  Generated data for 25 districts\n",
      "✓ Saved: market_infrastructure.csv (25 records)\n",
      "\n",
      "[4/4] GENERATING HOUSEHOLD SURVEY DATA...\n",
      "\n",
      "============================================================\n",
      "GENERATING HOUSEHOLD SURVEY DATA\n",
      "============================================================\n",
      "\n",
      "[1] Generating data for 15 districts...\n",
      "  District: Ratnapura - 41 households\n",
      "  District: Mannar - 10 households\n",
      "  District: Hambantota - 22 households\n",
      "  District: Galle - 40 households\n",
      "  District: Jaffna - 22 households\n",
      "  District: Badulla - 31 households\n",
      "  District: Ampara - 24 households\n",
      "  District: Kalutara - 46 households\n",
      "  District: Gampaha - 87 households\n",
      "  District: Nuwara Eliya - 27 households\n",
      "  District: Vavuniya - 10 households\n",
      "  District: Anuradhapura - 32 households\n",
      "  District: Colombo - 88 households\n",
      "  District: Kandy - 52 households\n",
      "  District: Puttalam - 29 households\n",
      "\n",
      "[2] Generated 561 households\n",
      "    Generated 5609 vegetable consumption records\n",
      "✓ Saved: household_survey_profiles.csv (561 records)\n",
      "✓ Saved: household_vegetable_consumption.csv (5609 records)\n",
      "✓ Saved: household_vegetable_survey_merged.csv (5609 records)\n",
      "Error creating summary report: Invalid format specifier ', if census_df is not None and 'population' in census_df.columns else 'N/A'' for object of type 'int'\n",
      "\n",
      "============================================================\n",
      "SCRAPING COMPLETE!\n",
      "============================================================\n",
      "Success Rate: 4.0/4 datasets\n",
      "End Time: 2026-01-18 22:12:15\n",
      "✅ SUCCESS: Most datasets created successfully!\n",
      "\n",
      "Files saved in: u:\\AIDS\\STAGE 2\\DSGP\\Ideas\\Price Prediction Magic\\Datasets\\Nutrition Profiling Dataset\\scraped_data\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sri Lanka District Data Scraping System\n",
    "Complete and Robust Web Scraping for All Required Datasets\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION & SETTINGS\n",
    "# ============================================================================\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuration settings for the scraping system\"\"\"\n",
    "    \n",
    "    # Districts of Sri Lanka\n",
    "    DISTRICTS = [\n",
    "        'Colombo', 'Gampaha', 'Kalutara', 'Kandy', 'Matale', 'Nuwara Eliya',\n",
    "        'Galle', 'Matara', 'Hambantota', 'Jaffna', 'Kilinochchi', 'Mannar',\n",
    "        'Mullaitivu', 'Vavuniya', 'Batticaloa', 'Ampara', 'Trincomalee',\n",
    "        'Kurunegala', 'Puttalam', 'Anuradhapura', 'Polonnaruwa',\n",
    "        'Badulla', 'Monaragala', 'Ratnapura', 'Kegalle'\n",
    "    ]\n",
    "    \n",
    "    # Provinces mapping\n",
    "    PROVINCE_MAP = {\n",
    "        'Colombo': 'Western', 'Gampaha': 'Western', 'Kalutara': 'Western',\n",
    "        'Kandy': 'Central', 'Matale': 'Central', 'Nuwara Eliya': 'Central',\n",
    "        'Galle': 'Southern', 'Matara': 'Southern', 'Hambantota': 'Southern',\n",
    "        'Jaffna': 'Northern', 'Kilinochchi': 'Northern', 'Mannar': 'Northern',\n",
    "        'Mullaitivu': 'Northern', 'Vavuniya': 'Northern',\n",
    "        'Batticaloa': 'Eastern', 'Ampara': 'Eastern', 'Trincomalee': 'Eastern',\n",
    "        'Kurunegala': 'North Western', 'Puttalam': 'North Western',\n",
    "        'Anuradhapura': 'North Central', 'Polonnaruwa': 'North Central',\n",
    "        'Badulla': 'Uva', 'Monaragala': 'Uva',\n",
    "        'Ratnapura': 'Sabaragamuwa', 'Kegalle': 'Sabaragamuwa'\n",
    "    }\n",
    "    \n",
    "    # Population data (2021 estimates)\n",
    "    POPULATION_DATA = {\n",
    "        'Colombo': 2323876, 'Gampaha': 2304872, 'Kalutara': 1224958,\n",
    "        'Kandy': 1376828, 'Matale': 484531, 'Nuwara Eliya': 711644,\n",
    "        'Galle': 1063342, 'Matara': 814048, 'Hambantota': 599903,\n",
    "        'Jaffna': 583882, 'Kilinochchi': 112875, 'Mannar': 99570,\n",
    "        'Mullaitivu': 92238, 'Vavuniya': 172115,\n",
    "        'Batticaloa': 526567, 'Ampara': 649402, 'Trincomalee': 379541,\n",
    "        'Kurunegala': 1618376, 'Puttalam': 762396,\n",
    "        'Anuradhapura': 860575, 'Polonnaruwa': 406088,\n",
    "        'Badulla': 815405, 'Monaragala': 451058,\n",
    "        'Ratnapura': 1088297, 'Kegalle': 840648\n",
    "    }\n",
    "    \n",
    "    # Area data (sq km)\n",
    "    AREA_DATA = {\n",
    "        'Colombo': 699, 'Gampaha': 1387, 'Kalutara': 1608,\n",
    "        'Kandy': 1940, 'Matale': 1993, 'Nuwara Eliya': 1741,\n",
    "        'Galle': 1652, 'Matara': 1283, 'Hambantota': 2609,\n",
    "        'Jaffna': 1025, 'Kilinochchi': 1279, 'Mannar': 1996,\n",
    "        'Mullaitivu': 2617, 'Vavuniya': 1967,\n",
    "        'Batticaloa': 2854, 'Ampara': 4415, 'Trincomalee': 2727,\n",
    "        'Kurunegala': 4816, 'Puttalam': 3072,\n",
    "        'Anuradhapura': 7179, 'Polonnaruwa': 3293,\n",
    "        'Badulla': 2861, 'Monaragala': 5639,\n",
    "        'Ratnapura': 3275, 'Kegalle': 1690\n",
    "    }\n",
    "    \n",
    "    # Urban percentage estimates\n",
    "    URBAN_PERCENTAGE = {\n",
    "        'Colombo': 100, 'Gampaha': 45, 'Kalutara': 25,\n",
    "        'Kandy': 35, 'Matale': 20, 'Nuwara Eliya': 15,\n",
    "        'Galle': 30, 'Matara': 25, 'Hambantota': 20,\n",
    "        'Jaffna': 40, 'Kilinochchi': 15, 'Mannar': 20,\n",
    "        'Mullaitivu': 10, 'Vavuniya': 25,\n",
    "        'Batticaloa': 30, 'Ampara': 20, 'Trincomalee': 25,\n",
    "        'Kurunegala': 20, 'Puttalam': 25,\n",
    "        'Anuradhapura': 20, 'Polonnaruwa': 15,\n",
    "        'Badulla': 20, 'Monaragala': 15,\n",
    "        'Ratnapura': 20, 'Kegalle': 15\n",
    "    }\n",
    "    \n",
    "    # Output directory\n",
    "    OUTPUT_DIR = 'scraped_data'\n",
    "    \n",
    "    # Request headers\n",
    "    HEADERS = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "        'Accept-Language': 'en-US,en;q=0.5',\n",
    "        'Accept-Encoding': 'gzip, deflate',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Upgrade-Insecure-Requests': '1'\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "class Utils:\n",
    "    \"\"\"Utility functions for data processing\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def safe_request(url, max_retries=3, timeout=30):\n",
    "        \"\"\"Make HTTP request with error handling and retries\"\"\"\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = requests.get(url, headers=Config.HEADERS, timeout=timeout)\n",
    "                response.raise_for_status()\n",
    "                return response\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    print(f\"Request failed after {max_retries} attempts: {e}\")\n",
    "                    return None\n",
    "                time.sleep(2 ** attempt)  # Exponential backoff\n",
    "        return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_numeric(text):\n",
    "        \"\"\"Extract numeric value from text\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return 0\n",
    "        text = str(text)\n",
    "        numbers = re.findall(r'[\\d,]+\\.?\\d*', text)\n",
    "        if numbers:\n",
    "            # Remove commas and convert to float\n",
    "            return float(numbers[0].replace(',', ''))\n",
    "        return 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_district(text):\n",
    "        \"\"\"Extract district name from text\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        for district in Config.DISTRICTS:\n",
    "            if district.lower() in text_lower:\n",
    "                return district\n",
    "        return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_text(text):\n",
    "        \"\"\"Clean and normalize text\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return ''\n",
    "        text = str(text).strip()\n",
    "        text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
    "        return text\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_density(population, area):\n",
    "        \"\"\"Calculate population density\"\"\"\n",
    "        if area > 0:\n",
    "            return population / area\n",
    "        return 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_dataframe(df, filename, output_dir=Config.OUTPUT_DIR):\n",
    "        \"\"\"Save DataFrame to CSV with error handling\"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        try:\n",
    "            df.to_csv(filepath, index=False, encoding='utf-8')\n",
    "            print(f\"✓ Saved: {filename} ({len(df)} records)\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error saving {filename}: {e}\")\n",
    "            return False\n",
    "\n",
    "# ============================================================================\n",
    "# CENSUS DATA SCRAPER\n",
    "# ============================================================================\n",
    "\n",
    "class CensusScraper:\n",
    "    \"\"\"Scrape district census data\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape_census_data():\n",
    "        \"\"\"Scrape census data from multiple sources\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"SCRAPING CENSUS DATA\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        census_data = []\n",
    "        \n",
    "        # Source 1: Wikipedia (most reliable for basic data)\n",
    "        print(\"\\n[1] Checking Wikipedia...\")\n",
    "        wiki_data = CensusScraper.scrape_wikipedia()\n",
    "        if wiki_data:\n",
    "            census_data.extend(wiki_data)\n",
    "            print(f\"  Found data for {len(wiki_data)} districts\")\n",
    "        \n",
    "        # Source 2: World Bank API\n",
    "        print(\"\\n[2] Checking World Bank API...\")\n",
    "        wb_data = CensusScraper.scrape_worldbank()\n",
    "        if wb_data:\n",
    "            census_data.extend(wb_data)\n",
    "            print(f\"  Found API data for {len(wb_data)} districts\")\n",
    "        \n",
    "        # If no data scraped, generate from known data\n",
    "        if not census_data:\n",
    "            print(\"\\n[3] Generating data from known statistics...\")\n",
    "            census_data = CensusScraper.generate_census_data()\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(census_data)\n",
    "        \n",
    "        # Ensure all districts are covered\n",
    "        df = CensusScraper.ensure_complete_coverage(df)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape_wikipedia():\n",
    "        \"\"\"Scrape from Wikipedia\"\"\"\n",
    "        try:\n",
    "            url = \"https://en.wikipedia.org/wiki/Districts_of_Sri_Lanka\"\n",
    "            response = Utils.safe_request(url)\n",
    "            if not response:\n",
    "                return []\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            tables = soup.find_all('table', {'class': 'wikitable'})\n",
    "            \n",
    "            data = []\n",
    "            for table in tables:\n",
    "                try:\n",
    "                    df_list = pd.read_html(str(table))\n",
    "                    if df_list:\n",
    "                        df = df_list[0]\n",
    "                        # Check if this is the districts table\n",
    "                        if 'District' in str(df.columns) and 'Population' in str(df.columns):\n",
    "                            for _, row in df.iterrows():\n",
    "                                district_name = Utils.clean_text(row.get('District', ''))\n",
    "                                district = Utils.extract_district(district_name)\n",
    "                                \n",
    "                                if district:\n",
    "                                    population = Utils.extract_numeric(row.get('Population', 0))\n",
    "                                    area = Utils.extract_numeric(row.get('Area (km²)', row.get('Area', 0)))\n",
    "                                    density = Utils.extract_numeric(row.get('Density', 0))\n",
    "                                    \n",
    "                                    data.append({\n",
    "                                        'district': district,\n",
    "                                        'population': population,\n",
    "                                        'area_sq_km': area,\n",
    "                                        'density_per_sqkm': density,\n",
    "                                        'source': 'Wikipedia'\n",
    "                                    })\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "            \n",
    "            return data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Wikipedia scrape failed: {e}\")\n",
    "            return []\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape_worldbank():\n",
    "        \"\"\"Get population data from World Bank (country level only)\"\"\"\n",
    "        try:\n",
    "            # World Bank API for Sri Lanka population\n",
    "            url = \"http://api.worldbank.org/v2/country/LKA/indicator/SP.POP.TOTL?format=json\"\n",
    "            response = Utils.safe_request(url)\n",
    "            if not response:\n",
    "                return []\n",
    "            \n",
    "            wb_data = response.json()\n",
    "            if len(wb_data) > 1:\n",
    "                latest_pop = wb_data[1][0]['value'] if wb_data[1] else 0\n",
    "                \n",
    "                # Distribute population to districts proportionally\n",
    "                data = []\n",
    "                total_known_pop = sum(Config.POPULATION_DATA.values())\n",
    "                \n",
    "                for district in Config.DISTRICTS:\n",
    "                    if total_known_pop > 0:\n",
    "                        # Adjust based on known distribution\n",
    "                        proportion = Config.POPULATION_DATA.get(district, 0) / total_known_pop\n",
    "                        population = int(latest_pop * proportion)\n",
    "                    else:\n",
    "                        population = Config.POPULATION_DATA.get(district, 0)\n",
    "                    \n",
    "                    data.append({\n",
    "                        'district': district,\n",
    "                        'population': population,\n",
    "                        'area_sq_km': Config.AREA_DATA.get(district, 0),\n",
    "                        'density_per_sqkm': Utils.calculate_density(population, Config.AREA_DATA.get(district, 1)),\n",
    "                        'source': 'WorldBank API (Estimated)'\n",
    "                    })\n",
    "                \n",
    "                return data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  WorldBank API failed: {e}\")\n",
    "            return []\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_census_data():\n",
    "        \"\"\"Generate census data from known statistics\"\"\"\n",
    "        data = []\n",
    "        \n",
    "        for district in Config.DISTRICTS:\n",
    "            population = Config.POPULATION_DATA.get(district, 0)\n",
    "            area = Config.AREA_DATA.get(district, 0)\n",
    "            \n",
    "            data.append({\n",
    "                'district': district,\n",
    "                'province': Config.PROVINCE_MAP.get(district, 'Unknown'),\n",
    "                'population': population,\n",
    "                'area_sq_km': area,\n",
    "                'density_per_sqkm': Utils.calculate_density(population, area),\n",
    "                'urban_population_pct': Config.URBAN_PERCENTAGE.get(district, 20),\n",
    "                'avg_household_size': round(np.random.uniform(3.5, 4.5), 1),\n",
    "                'population_growth_rate': round(np.random.uniform(0.5, 1.5), 2),\n",
    "                'source': 'Generated from known statistics'\n",
    "            })\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def ensure_complete_coverage(df):\n",
    "        \"\"\"Ensure all districts are covered\"\"\"\n",
    "        covered_districts = set(df['district'].unique()) if not df.empty else set()\n",
    "        all_districts = set(Config.DISTRICTS)\n",
    "        \n",
    "        missing_districts = all_districts - covered_districts\n",
    "        \n",
    "        if missing_districts:\n",
    "            print(f\"  Adding {len(missing_districts)} missing districts...\")\n",
    "            missing_data = []\n",
    "            \n",
    "            for district in missing_districts:\n",
    "                population = Config.POPULATION_DATA.get(district, 0)\n",
    "                area = Config.AREA_DATA.get(district, 0)\n",
    "                \n",
    "                missing_data.append({\n",
    "                    'district': district,\n",
    "                    'province': Config.PROVINCE_MAP.get(district, 'Unknown'),\n",
    "                    'population': population,\n",
    "                    'area_sq_km': area,\n",
    "                    'density_per_sqkm': Utils.calculate_density(population, area),\n",
    "                    'urban_population_pct': Config.URBAN_PERCENTAGE.get(district, 20),\n",
    "                    'avg_household_size': round(np.random.uniform(3.5, 4.5), 1),\n",
    "                    'population_growth_rate': round(np.random.uniform(0.5, 1.5), 2),\n",
    "                    'source': 'Generated (missing)'\n",
    "                })\n",
    "            \n",
    "            missing_df = pd.DataFrame(missing_data)\n",
    "            df = pd.concat([df, missing_df], ignore_index=True)\n",
    "        \n",
    "        # Add ethnic and religious composition (estimated)\n",
    "        df = CensusScraper.add_demographic_composition(df)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_demographic_composition(df):\n",
    "        \"\"\"Add estimated demographic composition\"\"\"\n",
    "        \n",
    "        def get_ethnic_composition(district):\n",
    "            \"\"\"Get ethnic composition based on district characteristics\"\"\"\n",
    "            province = Config.PROVINCE_MAP.get(district, '')\n",
    "            \n",
    "            if province == 'Northern':\n",
    "                return {'sinhala_pct': 5, 'tamil_pct': 90, 'muslim_pct': 5}\n",
    "            elif province == 'Eastern':\n",
    "                return {'sinhala_pct': 25, 'tamil_pct': 40, 'muslim_pct': 35}\n",
    "            elif 'Colombo' in district or 'Gampaha' in district:\n",
    "                return {'sinhala_pct': 80, 'tamil_pct': 10, 'muslim_pct': 10}\n",
    "            else:\n",
    "                return {'sinhala_pct': 85, 'tamil_pct': 10, 'muslim_pct': 5}\n",
    "        \n",
    "        def get_religious_composition(district):\n",
    "            \"\"\"Get religious composition\"\"\"\n",
    "            ethnic = get_ethnic_composition(district)\n",
    "            \n",
    "            # Estimate religious composition from ethnic\n",
    "            return {\n",
    "                'buddhist_pct': ethnic['sinhala_pct'] * 0.95,\n",
    "                'hindu_pct': ethnic['tamil_pct'] * 0.85,\n",
    "                'muslim_pct': ethnic['muslim_pct'] * 0.95,\n",
    "                'christian_pct': 100 - (ethnic['sinhala_pct'] * 0.95 + \n",
    "                                       ethnic['tamil_pct'] * 0.85 + \n",
    "                                       ethnic['muslim_pct'] * 0.95)\n",
    "            }\n",
    "        \n",
    "        # Apply to each district\n",
    "        ethnic_data = []\n",
    "        religious_data = []\n",
    "        \n",
    "        for district in df['district']:\n",
    "            ethnic = get_ethnic_composition(district)\n",
    "            religious = get_religious_composition(district)\n",
    "            \n",
    "            ethnic_data.append(ethnic)\n",
    "            religious_data.append(religious)\n",
    "        \n",
    "        # Convert to DataFrames and merge\n",
    "        ethnic_df = pd.DataFrame(ethnic_data)\n",
    "        religious_df = pd.DataFrame(religious_data)\n",
    "        \n",
    "        # Combine all data\n",
    "        result = pd.concat([df.reset_index(drop=True), ethnic_df, religious_df], axis=1)\n",
    "        \n",
    "        return result\n",
    "\n",
    "# ============================================================================\n",
    "# AGRICULTURE DATA SCRAPER\n",
    "# ============================================================================\n",
    "\n",
    "class AgricultureScraper:\n",
    "    \"\"\"Scrape agriculture production data\"\"\"\n",
    "    \n",
    "    # Major crops in Sri Lanka\n",
    "    CROPS = ['Paddy', 'Vegetables', 'Fruits', 'Tea', 'Rubber', 'Coconut', 'Spices', 'Cereals']\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape_agriculture_data():\n",
    "        \"\"\"Scrape agriculture data\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"SCRAPING AGRICULTURE DATA\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        agriculture_data = []\n",
    "        \n",
    "        # Source 1: FAO Data\n",
    "        print(\"\\n[1] Checking FAO data...\")\n",
    "        fao_data = AgricultureScraper.scrape_fao()\n",
    "        if fao_data:\n",
    "            agriculture_data.extend(fao_data)\n",
    "            print(f\"  Found {len(fao_data)} records from FAO\")\n",
    "        \n",
    "        # Source 2: Generate synthetic data based on district characteristics\n",
    "        print(\"\\n[2] Generating district-level agriculture data...\")\n",
    "        synthetic_data = AgricultureScraper.generate_agriculture_data()\n",
    "        agriculture_data.extend(synthetic_data)\n",
    "        print(f\"  Generated {len(synthetic_data)} synthetic records\")\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(agriculture_data)\n",
    "        \n",
    "        # Clean and validate\n",
    "        df = AgricultureScraper.clean_agriculture_data(df)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape_fao():\n",
    "        \"\"\"Scrape FAO agriculture data\"\"\"\n",
    "        try:\n",
    "            # FAO country profile for Sri Lanka\n",
    "            url = \"https://www.fao.org/faostat/en/#country/144\"\n",
    "            response = Utils.safe_request(url)\n",
    "            if not response:\n",
    "                return []\n",
    "            \n",
    "            # Note: FAO website is complex. For simplicity, we'll generate data\n",
    "            # based on known Sri Lankan agriculture statistics\n",
    "            \n",
    "            return []\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  FAO scrape failed: {e}\")\n",
    "            return []\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_agriculture_data():\n",
    "        \"\"\"Generate agriculture data based on district characteristics\"\"\"\n",
    "        data = []\n",
    "        \n",
    "        # Agricultural production zones\n",
    "        paddy_zones = ['Ampara', 'Polonnaruwa', 'Kurunegala', 'Anuradhapura', 'Hambantota']\n",
    "        vegetable_zones = ['Nuwara Eliya', 'Badulla', 'Kandy', 'Matale']\n",
    "        tea_zones = ['Nuwara Eliya', 'Kandy', 'Badulla', 'Ratnapura']\n",
    "        coconut_zones = ['Kurunegala', 'Puttalam', 'Gampaha', 'Colombo']\n",
    "        spice_zones = ['Matale', 'Kandy', 'Kegalle', 'Ratnapura']\n",
    "        \n",
    "        for district in Config.DISTRICTS:\n",
    "            # Determine district type for production scaling\n",
    "            urban_pct = Config.URBAN_PERCENTAGE.get(district, 20)\n",
    "            area = Config.AREA_DATA.get(district, 0)\n",
    "            \n",
    "            # Base agricultural area (percentage of total area)\n",
    "            if urban_pct > 50:\n",
    "                agri_area_pct = 0.3  # Urban districts have less agriculture\n",
    "            elif urban_pct > 20:\n",
    "                agri_area_pct = 0.5\n",
    "            else:\n",
    "                agri_area_pct = 0.7  # Rural districts have more agriculture\n",
    "            \n",
    "            total_agri_area = area * agri_area_pct\n",
    "            \n",
    "            for crop in AgricultureScraper.CROPS:\n",
    "                # Determine if district is major producer\n",
    "                is_major = (\n",
    "                    (crop == 'Paddy' and district in paddy_zones) or\n",
    "                    (crop == 'Vegetables' and district in vegetable_zones) or\n",
    "                    (crop == 'Tea' and district in tea_zones) or\n",
    "                    (crop == 'Coconut' and district in coconut_zones) or\n",
    "                    (crop == 'Spices' and district in spice_zones)\n",
    "                )\n",
    "                \n",
    "                # Area allocation\n",
    "                if is_major:\n",
    "                    crop_area = total_agri_area * 0.4  # Major crop gets 40%\n",
    "                else:\n",
    "                    crop_area = total_agri_area * 0.05  # Minor crop gets 5%\n",
    "                \n",
    "                # Yield per hectare (tons)\n",
    "                yield_map = {\n",
    "                    'Paddy': 4.2, 'Vegetables': 8.5, 'Fruits': 12.0,\n",
    "                    'Tea': 1.8, 'Rubber': 1.2, 'Coconut': 0.8,\n",
    "                    'Spices': 2.5, 'Cereals': 3.0\n",
    "                }\n",
    "                yield_per_ha = yield_map.get(crop, 3.0)\n",
    "                \n",
    "                # Production\n",
    "                production = crop_area * yield_per_ha\n",
    "                \n",
    "                # Harvest seasons\n",
    "                season_map = {\n",
    "                    'Paddy': 'Maha & Yala',\n",
    "                    'Vegetables': 'Year-round',\n",
    "                    'Fruits': 'Seasonal',\n",
    "                    'Tea': 'Year-round',\n",
    "                    'Rubber': 'Year-round',\n",
    "                    'Coconut': 'Year-round',\n",
    "                    'Spices': 'Year-round',\n",
    "                    'Cereals': 'Maha'\n",
    "                }\n",
    "                \n",
    "                data.append({\n",
    "                    'district': district,\n",
    "                    'crop_type': crop,\n",
    "                    'area_ha': round(crop_area),\n",
    "                    'production_mt': round(production),\n",
    "                    'yield_mt_ha': round(yield_per_ha, 2),\n",
    "                    'harvest_season': season_map.get(crop, 'Year-round'),\n",
    "                    'organic_area_ha': round(crop_area * 0.1),  # Assume 10% organic\n",
    "                    'irrigated_area_ha': round(crop_area * 0.6),  # Assume 60% irrigated\n",
    "                    'is_major_producer': is_major,\n",
    "                    'data_source': 'Generated based on district characteristics'\n",
    "                })\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_agriculture_data(df):\n",
    "        \"\"\"Clean and validate agriculture data\"\"\"\n",
    "        # Ensure numeric columns\n",
    "        numeric_cols = ['area_ha', 'production_mt', 'yield_mt_ha', \n",
    "                       'organic_area_ha', 'irrigated_area_ha']\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "        \n",
    "        # Ensure positive values\n",
    "        for col in numeric_cols:\n",
    "            df[col] = df[col].apply(lambda x: max(0, x))\n",
    "        \n",
    "        # Add calculated yield if missing\n",
    "        if 'yield_mt_ha' in df.columns and 'area_ha' in df.columns and 'production_mt' in df.columns:\n",
    "            mask = (df['yield_mt_ha'] == 0) & (df['area_ha'] > 0)\n",
    "            df.loc[mask, 'yield_mt_ha'] = df.loc[mask, 'production_mt'] / df.loc[mask, 'area_ha']\n",
    "        \n",
    "        return df\n",
    "\n",
    "# ============================================================================\n",
    "# MARKET INFRASTRUCTURE SCRAPER\n",
    "# ============================================================================\n",
    "\n",
    "class MarketScraper:\n",
    "    \"\"\"Scrape market infrastructure data\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape_market_data():\n",
    "        \"\"\"Scrape market infrastructure data\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"SCRAPING MARKET INFRASTRUCTURE DATA\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        market_data = []\n",
    "        \n",
    "        # Generate comprehensive market data\n",
    "        print(\"\\n[1] Generating market infrastructure data...\")\n",
    "        generated_data = MarketScraper.generate_market_data()\n",
    "        market_data.extend(generated_data)\n",
    "        print(f\"  Generated data for {len(generated_data)} districts\")\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(market_data)\n",
    "        \n",
    "        # Calculate derived metrics\n",
    "        df = MarketScraper.calculate_derived_metrics(df)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_market_data():\n",
    "        \"\"\"Generate market infrastructure data based on urbanization\"\"\"\n",
    "        data = []\n",
    "        \n",
    "        for district in Config.DISTRICTS:\n",
    "            urban_pct = Config.URBAN_PERCENTAGE.get(district, 20)\n",
    "            population = Config.POPULATION_DATA.get(district, 0)\n",
    "            \n",
    "            # Estimate market counts based on urbanization and population\n",
    "            if urban_pct > 70:  # Highly urban\n",
    "                supermarket_count = max(1, int(population / 25000))\n",
    "                market_count = max(3, int(population / 8000))\n",
    "                weekly_fair_count = max(2, int(population / 100000))\n",
    "                wholesale_count = 1 if population > 300000 else 0\n",
    "                cold_storage = True\n",
    "                access_time = np.random.randint(5, 20)\n",
    "                \n",
    "            elif urban_pct > 40:  # Moderately urban\n",
    "                supermarket_count = max(1, int(population / 40000))\n",
    "                market_count = max(2, int(population / 15000))\n",
    "                weekly_fair_count = max(1, int(population / 80000))\n",
    "                wholesale_count = 1 if population > 500000 else 0\n",
    "                cold_storage = urban_pct > 50\n",
    "                access_time = np.random.randint(15, 35)\n",
    "                \n",
    "            else:  # Rural\n",
    "                supermarket_count = max(0, int(population / 100000))\n",
    "                market_count = max(1, int(population / 25000))\n",
    "                weekly_fair_count = max(1, int(population / 60000))\n",
    "                wholesale_count = 0\n",
    "                cold_storage = False\n",
    "                access_time = np.random.randint(25, 60)\n",
    "            \n",
    "            # Ensure at least one market\n",
    "            market_count = max(1, market_count)\n",
    "            \n",
    "            # Road density (km per sq km)\n",
    "            if urban_pct > 70:\n",
    "                road_density = round(np.random.uniform(2.0, 4.0), 2)\n",
    "            elif urban_pct > 40:\n",
    "                road_density = round(np.random.uniform(1.0, 2.5), 2)\n",
    "            else:\n",
    "                road_density = round(np.random.uniform(0.3, 1.5), 2)\n",
    "            \n",
    "            data.append({\n",
    "                'district': district,\n",
    "                'urban_percentage': urban_pct,\n",
    "                'population': population,\n",
    "                'market_count': market_count,\n",
    "                'supermarket_count': supermarket_count,\n",
    "                'weekly_fair_count': weekly_fair_count,\n",
    "                'wholesale_market_count': wholesale_count,\n",
    "                'has_cold_storage': cold_storage,\n",
    "                'road_density_km_sqkm': road_density,\n",
    "                'avg_market_access_time_min': access_time,\n",
    "                'has_public_transport': urban_pct > 30,\n",
    "                'digital_market_access': urban_pct > 50,\n",
    "                'data_source': 'Generated based on urbanization'\n",
    "            })\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_derived_metrics(df):\n",
    "        \"\"\"Calculate derived market metrics\"\"\"\n",
    "        \n",
    "        # Total market facilities\n",
    "        df['total_market_facilities'] = (\n",
    "            df['market_count'] + \n",
    "            df['supermarket_count'] + \n",
    "            df['weekly_fair_count'] + \n",
    "            df['wholesale_market_count']\n",
    "        )\n",
    "        \n",
    "        # Market density per 100,000 people\n",
    "        df['market_density_per_100k'] = (\n",
    "            df['total_market_facilities'] / (df['population'] / 100000)\n",
    "        ).round(2)\n",
    "        \n",
    "        # Market access score (0-100)\n",
    "        def calculate_access_score(row):\n",
    "            score = 0\n",
    "            \n",
    "            # Market density component (max 40)\n",
    "            density = row['market_density_per_100k']\n",
    "            if density > 15:\n",
    "                score += 40\n",
    "            elif density > 10:\n",
    "                score += 30\n",
    "            elif density > 5:\n",
    "                score += 20\n",
    "            elif density > 2:\n",
    "                score += 10\n",
    "            \n",
    "            # Access time component (max 30)\n",
    "            access_time = row['avg_market_access_time_min']\n",
    "            if access_time < 15:\n",
    "                score += 30\n",
    "            elif access_time < 30:\n",
    "                score += 20\n",
    "            elif access_time < 45:\n",
    "                score += 10\n",
    "            \n",
    "            # Infrastructure component (max 30)\n",
    "            if row['has_cold_storage']:\n",
    "                score += 10\n",
    "            if row['has_public_transport']:\n",
    "                score += 10\n",
    "            if row['digital_market_access']:\n",
    "                score += 10\n",
    "            \n",
    "            return min(100, score)\n",
    "        \n",
    "        df['market_access_score'] = df.apply(calculate_access_score, axis=1)\n",
    "        \n",
    "        # Market type diversity\n",
    "        df['market_type_diversity'] = (\n",
    "            (df['supermarket_count'] > 0).astype(int) +\n",
    "            (df['weekly_fair_count'] > 0).astype(int) +\n",
    "            (df['wholesale_market_count'] > 0).astype(int) +\n",
    "            1  # Always have regular markets\n",
    "        )\n",
    "        \n",
    "        return df\n",
    "\n",
    "# ============================================================================\n",
    "# HOUSEHOLD SURVEY SCRAPER\n",
    "# ============================================================================\n",
    "\n",
    "class HouseholdSurveyScraper:\n",
    "    \"\"\"Generate household survey data\"\"\"\n",
    "    \n",
    "    # Common vegetables in Sri Lanka\n",
    "    VEGETABLES = [\n",
    "        'Cabbage', 'Carrot', 'Tomato', 'Onion', 'Potato', 'Green Chili',\n",
    "        'Brinjal', 'Okra', 'Long Beans', 'Pumpkin', 'Cucumber', 'Radish',\n",
    "        'Beetroot', 'Ladies Finger', 'Bitter Gourd', 'Snake Gourd',\n",
    "        'Drumstick', 'Spinach', 'Gotukola', 'Kankun', 'Mukunuwenna',\n",
    "        'Thampala', 'Kohila'\n",
    "    ]\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape_household_data(num_households=1000):\n",
    "        \"\"\"Generate household survey data\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"GENERATING HOUSEHOLD SURVEY DATA\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Sample districts (not all to keep data manageable)\n",
    "        sample_districts = np.random.choice(\n",
    "            Config.DISTRICTS, \n",
    "            size=min(15, len(Config.DISTRICTS)), \n",
    "            replace=False\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n[1] Generating data for {len(sample_districts)} districts...\")\n",
    "        \n",
    "        household_data = []\n",
    "        vegetable_consumption_data = []\n",
    "        \n",
    "        household_id = 1\n",
    "        \n",
    "        for district in sample_districts:\n",
    "            # Number of households in this district\n",
    "            district_population = Config.POPULATION_DATA.get(district, 0)\n",
    "            households_in_district = max(10, min(100, int(num_households * (district_population / 21000000))))\n",
    "            \n",
    "            print(f\"  District: {district} - {households_in_district} households\")\n",
    "            \n",
    "            for hh in range(households_in_district):\n",
    "                # Generate household profile\n",
    "                household = HouseholdSurveyScraper.generate_household_profile(\n",
    "                    household_id, district\n",
    "                )\n",
    "                \n",
    "                # Generate vegetable consumption for this household\n",
    "                consumption = HouseholdSurveyScraper.generate_vegetable_consumption(\n",
    "                    household_id, district, household\n",
    "                )\n",
    "                \n",
    "                household_data.append(household)\n",
    "                vegetable_consumption_data.extend(consumption)\n",
    "                \n",
    "                household_id += 1\n",
    "        \n",
    "        # Create DataFrames\n",
    "        households_df = pd.DataFrame(household_data)\n",
    "        consumption_df = pd.DataFrame(vegetable_consumption_data)\n",
    "        \n",
    "        print(f\"\\n[2] Generated {len(households_df)} households\")\n",
    "        print(f\"    Generated {len(consumption_df)} vegetable consumption records\")\n",
    "        \n",
    "        return households_df, consumption_df\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_household_profile(household_id, district):\n",
    "        \"\"\"Generate a household profile\"\"\"\n",
    "        \n",
    "        urban_pct = Config.URBAN_PERCENTAGE.get(district, 20)\n",
    "        \n",
    "        # Determine if household is urban or rural\n",
    "        is_urban = np.random.random() < (urban_pct / 100)\n",
    "        \n",
    "        # Income category probabilities based on urbanization\n",
    "        if is_urban:\n",
    "            income_probs = [0.2, 0.6, 0.2]  # Low, Middle, High\n",
    "        else:\n",
    "            income_probs = [0.4, 0.55, 0.05]\n",
    "        \n",
    "        income_category = np.random.choice(['Low', 'Middle', 'High'], p=income_probs)\n",
    "        \n",
    "        # Income ranges (LKR per month)\n",
    "        income_ranges = {\n",
    "            'Low': (15000, 50000),\n",
    "            'Middle': (50000, 150000),\n",
    "            'High': (150000, 500000)\n",
    "        }\n",
    "        \n",
    "        income_range = income_ranges[income_category]\n",
    "        monthly_income = np.random.randint(income_range[0], income_range[1])\n",
    "        \n",
    "        # Family size\n",
    "        if is_urban:\n",
    "            family_size = np.random.randint(2, 5)\n",
    "        else:\n",
    "            family_size = np.random.randint(3, 7)\n",
    "        \n",
    "        # Has vegetable garden (more likely in rural areas)\n",
    "        if is_urban:\n",
    "            has_garden_prob = 0.2\n",
    "        else:\n",
    "            has_garden_prob = 0.6\n",
    "        \n",
    "        has_vegetable_garden = np.random.random() < has_garden_prob\n",
    "        \n",
    "        # Dietary preference\n",
    "        dietary_options = ['Vegetarian', 'Non-vegetarian', 'Mixed']\n",
    "        if is_urban:\n",
    "            dietary_probs = [0.15, 0.60, 0.25]\n",
    "        else:\n",
    "            dietary_probs = [0.10, 0.70, 0.20]\n",
    "        \n",
    "        dietary_preference = np.random.choice(dietary_options, p=dietary_probs)\n",
    "        \n",
    "        # Cooking frequency\n",
    "        cooking_options = ['Daily', '5-6 times/week', '3-4 times/week', 'Rarely']\n",
    "        cooking_probs = [0.7, 0.2, 0.08, 0.02] if is_urban else [0.8, 0.15, 0.04, 0.01]\n",
    "        cooking_frequency = np.random.choice(cooking_options, p=cooking_probs)\n",
    "        \n",
    "        # Market access time\n",
    "        if is_urban:\n",
    "            market_access_time = np.random.randint(5, 25)\n",
    "        else:\n",
    "            market_access_time = np.random.randint(15, 60)\n",
    "        \n",
    "        # Preferred shopping location\n",
    "        shopping_options = ['Supermarket', 'Local Market', 'Roadside Vendor', 'Weekly Fair']\n",
    "        if is_urban:\n",
    "            shopping_probs = [0.4, 0.3, 0.2, 0.1]\n",
    "        else:\n",
    "            shopping_probs = [0.1, 0.4, 0.3, 0.2]\n",
    "        \n",
    "        preferred_shopping = np.random.choice(shopping_options, p=shopping_probs)\n",
    "        \n",
    "        return {\n",
    "            'household_id': f\"HH{household_id:04d}\",\n",
    "            'district': district,\n",
    "            'province': Config.PROVINCE_MAP.get(district, 'Unknown'),\n",
    "            'urban_rural': 'Urban' if is_urban else 'Rural',\n",
    "            'income_category': income_category,\n",
    "            'monthly_income_lkr': monthly_income,\n",
    "            'family_size': family_size,\n",
    "            'has_vegetable_garden': has_vegetable_garden,\n",
    "            'dietary_preference': dietary_preference,\n",
    "            'cooking_frequency': cooking_frequency,\n",
    "            'market_access_time_min': market_access_time,\n",
    "            'preferred_shopping_location': preferred_shopping,\n",
    "            'weekly_food_budget_lkr': int(monthly_income * 0.3 / 4.33),  # 30% of income, weekly\n",
    "            'data_source': 'Generated household survey'\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_vegetable_consumption(household_id, district, household_profile):\n",
    "        \"\"\"Generate vegetable consumption data for a household\"\"\"\n",
    "        \n",
    "        consumption_data = []\n",
    "        \n",
    "        # Select 8-12 vegetables that this household consumes\n",
    "        num_vegetables = np.random.randint(8, 13)\n",
    "        household_vegetables = np.random.choice(\n",
    "            HouseholdSurveyScraper.VEGETABLES, \n",
    "            size=num_vegetables, \n",
    "            replace=False\n",
    "        )\n",
    "        \n",
    "        urban_rural = household_profile['urban_rural']\n",
    "        income_category = household_profile['income_category']\n",
    "        \n",
    "        for vegetable in household_vegetables:\n",
    "            # Consumption frequency\n",
    "            freq_options = ['Daily', '4-6 times/week', '2-3 times/week', 'Weekly', 'Monthly']\n",
    "            \n",
    "            if vegetable in ['Onion', 'Tomato', 'Green Chili', 'Potato']:\n",
    "                # Common vegetables consumed more frequently\n",
    "                freq_probs = [0.3, 0.4, 0.2, 0.08, 0.02]\n",
    "            elif vegetable in ['Carrot', 'Cabbage', 'Brinjal', 'Okra']:\n",
    "                freq_probs = [0.1, 0.3, 0.4, 0.15, 0.05]\n",
    "            else:\n",
    "                freq_probs = [0.05, 0.2, 0.3, 0.3, 0.15]\n",
    "            \n",
    "            consumption_frequency = np.random.choice(freq_options, p=freq_probs)\n",
    "            \n",
    "            # Weekly quantity (kg)\n",
    "            base_quantity = {\n",
    "                'Daily': np.random.uniform(0.5, 2.0),\n",
    "                '4-6 times/week': np.random.uniform(0.3, 1.5),\n",
    "                '2-3 times/week': np.random.uniform(0.2, 1.0),\n",
    "                'Weekly': np.random.uniform(0.1, 0.5),\n",
    "                'Monthly': np.random.uniform(0.05, 0.2)\n",
    "            }\n",
    "            \n",
    "            quantity = base_quantity[consumption_frequency]\n",
    "            \n",
    "            # Adjust for income\n",
    "            income_multiplier = {'Low': 0.7, 'Middle': 1.0, 'High': 1.3}\n",
    "            quantity *= income_multiplier.get(income_category, 1.0)\n",
    "            \n",
    "            # Price per kg (LKR)\n",
    "            base_prices = {\n",
    "                'Onion': 120, 'Tomato': 150, 'Potato': 100, 'Carrot': 180,\n",
    "                'Cabbage': 80, 'Brinjal': 120, 'Okra': 200, 'Pumpkin': 60,\n",
    "                'Green Chili': 300, 'Cucumber': 100, 'Radish': 120,\n",
    "                'Beetroot': 150, 'Ladies Finger': 180, 'Bitter Gourd': 220,\n",
    "                'Snake Gourd': 140, 'Drumstick': 250, 'Spinach': 120,\n",
    "                'Gotukola': 180, 'Kankun': 160, 'Mukunuwenna': 170,\n",
    "                'Thampala': 140, 'Kohila': 200, 'Long Beans': 160\n",
    "            }\n",
    "            \n",
    "            price = base_prices.get(vegetable, 150)\n",
    "            \n",
    "            # Adjust price for urban areas (higher)\n",
    "            if urban_rural == 'Urban':\n",
    "                price *= 1.2\n",
    "            \n",
    "            # Weekly expenditure\n",
    "            weekly_expenditure = quantity * price\n",
    "            \n",
    "            # Preparation method\n",
    "            prep_methods = ['Curry', 'Stir Fry', 'Salad', 'Boiled', 'Traditional Mallum', 'Pickled']\n",
    "            \n",
    "            if vegetable in ['Gotukola', 'Kankun', 'Mukunuwenna', 'Thampala']:\n",
    "                preparation = 'Traditional Mallum'\n",
    "            elif vegetable in ['Onion', 'Tomato', 'Cucumber']:\n",
    "                preparation = np.random.choice(['Salad', 'Curry', 'Stir Fry'], p=[0.6, 0.3, 0.1])\n",
    "            elif vegetable in ['Carrot', 'Potato', 'Pumpkin']:\n",
    "                preparation = np.random.choice(['Curry', 'Boiled', 'Stir Fry'], p=[0.7, 0.2, 0.1])\n",
    "            else:\n",
    "                preparation = np.random.choice(prep_methods)\n",
    "            \n",
    "            # Purchase location\n",
    "            preferred_location = household_profile['preferred_shopping_location']\n",
    "            \n",
    "            consumption_data.append({\n",
    "                'household_id': f\"HH{household_id:04d}\",\n",
    "                'district': district,\n",
    "                'vegetable': vegetable,\n",
    "                'consumption_frequency': consumption_frequency,\n",
    "                'weekly_quantity_kg': round(quantity, 2),\n",
    "                'price_per_kg_lkr': round(price, 2),\n",
    "                'weekly_expenditure_lkr': round(weekly_expenditure, 2),\n",
    "                'preparation_method': preparation,\n",
    "                'purchase_location': preferred_location,\n",
    "                'is_organic': np.random.random() < 0.2,  # 20% buy organic\n",
    "                'seasonal_availability': HouseholdSurveyScraper.get_seasonality(vegetable),\n",
    "                'preference_rating': np.random.randint(6, 11),  # 6-10 scale\n",
    "                'data_source': 'Generated consumption survey'\n",
    "            })\n",
    "        \n",
    "        return consumption_data\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_seasonality(vegetable):\n",
    "        \"\"\"Get seasonal availability for vegetable\"\"\"\n",
    "        seasonal_map = {\n",
    "            'Pumpkin': 'Year-round',\n",
    "            'Carrot': 'Year-round',\n",
    "            'Potato': 'Year-round',\n",
    "            'Onion': 'Year-round',\n",
    "            'Tomato': 'Year-round',\n",
    "            'Cabbage': 'Year-round',\n",
    "            'Brinjal': 'Year-round',\n",
    "            'Okra': 'Year-round',\n",
    "            'Green Chili': 'Year-round',\n",
    "            'Gotukola': 'Year-round',\n",
    "            'Kankun': 'Year-round',\n",
    "            'Mukunuwenna': 'Year-round',\n",
    "            'Thampala': 'Year-round',\n",
    "            'Cucumber': 'Dry Season',\n",
    "            'Radish': 'Cool Season',\n",
    "            'Beetroot': 'Cool Season',\n",
    "            'Bitter Gourd': 'Wet Season',\n",
    "            'Snake Gourd': 'Wet Season',\n",
    "            'Drumstick': 'Dry Season',\n",
    "            'Spinach': 'Cool Season',\n",
    "            'Kohila': 'Wet Season',\n",
    "            'Long Beans': 'Year-round'\n",
    "        }\n",
    "        return seasonal_map.get(vegetable, 'Year-round')\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "class DataScrapingSystem:\n",
    "    \"\"\"Main data scraping system\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def run():\n",
    "        \"\"\"Run the complete data scraping system\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"SRI LANKA DISTRICT DATA SCRAPING SYSTEM\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Create output directory\n",
    "        os.makedirs(Config.OUTPUT_DIR, exist_ok=True)\n",
    "        \n",
    "        # Track success\n",
    "        success_count = 0\n",
    "        total_datasets = 4\n",
    "        \n",
    "        try:\n",
    "            # 1. Scrape Census Data\n",
    "            print(\"\\n[1/4] SCRAPING CENSUS DATA...\")\n",
    "            census_df = CensusScraper.scrape_census_data()\n",
    "            if Utils.save_dataframe(census_df, 'sri_lanka_district_census.csv'):\n",
    "                success_count += 1\n",
    "            \n",
    "            # 2. Scrape Agriculture Data\n",
    "            print(\"\\n[2/4] SCRAPING AGRICULTURE DATA...\")\n",
    "            agriculture_df = AgricultureScraper.scrape_agriculture_data()\n",
    "            if Utils.save_dataframe(agriculture_df, 'district_agriculture_data.csv'):\n",
    "                success_count += 1\n",
    "            \n",
    "            # 3. Scrape Market Infrastructure Data\n",
    "            print(\"\\n[3/4] SCRAPING MARKET INFRASTRUCTURE DATA...\")\n",
    "            market_df = MarketScraper.scrape_market_data()\n",
    "            if Utils.save_dataframe(market_df, 'market_infrastructure.csv'):\n",
    "                success_count += 1\n",
    "            \n",
    "            # 4. Generate Household Survey Data\n",
    "            print(\"\\n[4/4] GENERATING HOUSEHOLD SURVEY DATA...\")\n",
    "            households_df, consumption_df = HouseholdSurveyScraper.scrape_household_data(num_households=800)\n",
    "            \n",
    "            # Save both household and consumption data\n",
    "            if Utils.save_dataframe(households_df, 'household_survey_profiles.csv'):\n",
    "                success_count += 0.5\n",
    "            \n",
    "            if Utils.save_dataframe(consumption_df, 'household_vegetable_consumption.csv'):\n",
    "                success_count += 0.5\n",
    "            \n",
    "            # Create merged household survey file\n",
    "            try:\n",
    "                merged_df = pd.merge(\n",
    "                    households_df,\n",
    "                    consumption_df,\n",
    "                    on=['household_id', 'district'],\n",
    "                    how='inner'\n",
    "                )\n",
    "                Utils.save_dataframe(merged_df, 'household_vegetable_survey_merged.csv')\n",
    "            except Exception as e:\n",
    "                print(f\"  Note: Could not merge household data: {e}\")\n",
    "            \n",
    "            # Create summary report\n",
    "            DataScrapingSystem.create_summary_report(\n",
    "                census_df, agriculture_df, market_df, \n",
    "                households_df, consumption_df\n",
    "            )\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"SCRAPING COMPLETE!\")\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"Success Rate: {success_count}/{total_datasets} datasets\")\n",
    "            print(f\"End Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "            \n",
    "            if success_count >= total_datasets * 0.75:\n",
    "                print(\"✅ SUCCESS: Most datasets created successfully!\")\n",
    "            elif success_count >= total_datasets * 0.5:\n",
    "                print(\"⚠️  PARTIAL SUCCESS: Some datasets created\")\n",
    "            else:\n",
    "                print(\"❌ LIMITED SUCCESS: Few datasets created\")\n",
    "            \n",
    "            print(f\"\\nFiles saved in: {os.path.abspath(Config.OUTPUT_DIR)}\")\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\n⚠️  Scraping interrupted by user\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n\\n❌ Critical error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_summary_report(census_df, agriculture_df, market_df, households_df, consumption_df):\n",
    "        \"\"\"Create a comprehensive summary report\"\"\"\n",
    "        \n",
    "        try:\n",
    "            report = f\"\"\"\n",
    "================================================================================\n",
    "SRI LANKA DISTRICT DATA SCRAPING - SUMMARY REPORT\n",
    "================================================================================\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "================================================================================\n",
    "\n",
    "1. CENSUS DATA\n",
    "---------------\n",
    "- Districts Covered: {len(census_df) if census_df is not None else 0}\n",
    "- Total Population: {census_df['population'].sum():, if census_df is not None and 'population' in census_df.columns else 'N/A'}\n",
    "- Average Density: {census_df['density_per_sqkm'].mean():.1f if census_df is not None and 'density_per_sqkm' in census_df.columns else 'N/A'} per sq km\n",
    "- Urban Population: {census_df['urban_population_pct'].mean():.1f if census_df is not None and 'urban_population_pct' in census_df.columns else 'N/A'}% avg\n",
    "\n",
    "2. AGRICULTURE DATA\n",
    "-------------------\n",
    "- Total Records: {len(agriculture_df) if agriculture_df is not None else 0}\n",
    "- Crops Covered: {agriculture_df['crop_type'].nunique() if agriculture_df is not None and 'crop_type' in agriculture_df.columns else 'N/A'}\n",
    "- Districts Covered: {agriculture_df['district'].nunique() if agriculture_df is not None and 'district' in agriculture_df.columns else 'N/A'}\n",
    "- Total Agricultural Area: {agriculture_df['area_ha'].sum():, if agriculture_df is not None and 'area_ha' in agriculture_df.columns else 'N/A'} ha\n",
    "\n",
    "3. MARKET INFRASTRUCTURE\n",
    "------------------------\n",
    "- Districts Covered: {len(market_df) if market_df is not None else 0}\n",
    "- Total Markets: {market_df['total_market_facilities'].sum() if market_df is not None and 'total_market_facilities' in market_df.columns else 'N/A'}\n",
    "- Supermarkets: {market_df['supermarket_count'].sum() if market_df is not None and 'supermarket_count' in market_df.columns else 'N/A'}\n",
    "- Average Market Access Score: {market_df['market_access_score'].mean():.1f if market_df is not None and 'market_access_score' in market_df.columns else 'N/A'}/100\n",
    "\n",
    "4. HOUSEHOLD SURVEY DATA\n",
    "------------------------\n",
    "- Households Surveyed: {len(households_df) if households_df is not None else 0}\n",
    "- Vegetable Consumption Records: {len(consumption_df) if consumption_df is not None else 0}\n",
    "- Districts Covered: {households_df['district'].nunique() if households_df is not None and 'district' in households_df.columns else 'N/A'}\n",
    "- Unique Vegetables: {consumption_df['vegetable'].nunique() if consumption_df is not None and 'vegetable' in consumption_df.columns else 'N/A'}\n",
    "- Average Weekly Veg Expenditure: LKR {consumption_df['weekly_expenditure_lkr'].mean():.0f if consumption_df is not None and 'weekly_expenditure_lkr' in consumption_df.columns else 'N/A'}\n",
    "\n",
    "================================================================================\n",
    "DATA QUALITY ASSESSMENT\n",
    "================================================================================\n",
    "- Census Data: {'✅ COMPLETE' if census_df is not None and len(census_df) >= 20 else '⚠️  PARTIAL' if census_df is not None and len(census_df) >= 10 else '❌ INCOMPLETE'}\n",
    "- Agriculture Data: {'✅ DETAILED' if agriculture_df is not None and len(agriculture_df) > 100 else '⚠️  BASIC' if agriculture_df is not None and len(agriculture_df) > 50 else '❌ LIMITED'}\n",
    "- Market Data: {'✅ COMPREHENSIVE' if market_df is not None and len(market_df) >= 20 else '⚠️  ADEQUATE' if market_df is not None and len(market_df) >= 10 else '❌ LIMITED'}\n",
    "- Survey Data: {'✅ DETAILED' if consumption_df is not None and len(consumption_df) > 1000 else '⚠️  ADEQUATE' if consumption_df is not None and len(consumption_df) > 500 else '❌ LIMITED'}\n",
    "\n",
    "================================================================================\n",
    "RECOMMENDATIONS FOR USE\n",
    "================================================================================\n",
    "1. For research: Use census and agriculture data as primary sources\n",
    "2. For planning: Use market infrastructure data for accessibility analysis\n",
    "3. For recommendations: Use household survey data for preference modeling\n",
    "4. Validation: Cross-check with official government publications when available\n",
    "5. Updates: Refresh data annually for accurate recommendations\n",
    "\n",
    "================================================================================\n",
    "FILES CREATED\n",
    "================================================================================\n",
    "1. sri_lanka_district_census.csv           - District demographic data\n",
    "2. district_agriculture_data.csv           - Agricultural production data\n",
    "3. market_infrastructure.csv               - Market access and infrastructure\n",
    "4. household_survey_profiles.csv           - Household characteristics\n",
    "5. household_vegetable_consumption.csv     - Detailed vegetable consumption\n",
    "6. household_vegetable_survey_merged.csv   - Combined household data\n",
    "\n",
    "================================================================================\n",
    "\"\"\"\n",
    "            \n",
    "            report_path = os.path.join(Config.OUTPUT_DIR, 'scraping_summary_report.txt')\n",
    "            with open(report_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(report)\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"SUMMARY REPORT SAVED\")\n",
    "            print(\"=\" * 60)\n",
    "            print(report.split('================================================================================')[1])\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating summary report: {e}\")\n",
    "\n",
    "# ============================================================================\n",
    "# INSTALLATION CHECK\n",
    "# ============================================================================\n",
    "\n",
    "def check_dependencies():\n",
    "    \"\"\"Check and install required dependencies\"\"\"\n",
    "    \n",
    "    required = ['requests', 'pandas', 'numpy']\n",
    "    optional = ['beautifulsoup4']\n",
    "    \n",
    "    print(\"Checking dependencies...\")\n",
    "    \n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    for package in required:\n",
    "        try:\n",
    "            __import__(package)\n",
    "            print(f\"✅ {package}\")\n",
    "        except ImportError:\n",
    "            print(f\"📦 Installing {package}...\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "    \n",
    "    for package in optional:\n",
    "        try:\n",
    "            __import__(package.replace('-', '_'))\n",
    "            print(f\"✅ {package} (optional)\")\n",
    "        except ImportError:\n",
    "            print(f\"⚠️  {package} not installed (optional, some features limited)\")\n",
    "\n",
    "# ============================================================================\n",
    "# ENTRY POINT\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Sri Lanka District Data Scraping System\")\n",
    "    print(\"Version 2.0 - Complete and Robust\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Check dependencies\n",
    "    check_dependencies()\n",
    "    \n",
    "    # Run the scraping system\n",
    "    try:\n",
    "        DataScrapingSystem.run()\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Fatal error in main execution: {e}\")\n",
    "        print(\"Please check your internet connection and try again.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
