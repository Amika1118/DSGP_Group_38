{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bfde8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training proper XGBoost LTR model...\n",
      "Success! XGBoost LTR + Recipes generated for Tangalle.\n",
      "Top Recommended Veggie: CASSAVA,RAW\n",
      "Daily Affordability Gap: LKR 38.40\n",
      "Top Actionable Recipe: Spinach Curry\n",
      "Estimated Cost: LKR 122\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import ast\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 1. LOAD ALL DATASETS + NEW PRICE DATASETS\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "veggies = pd.read_csv('vegetables_USDA.csv')\n",
    "users = pd.read_csv('user_profiles_enhanced.csv')\n",
    "dist_profiles = pd.read_csv('final_datasets/district_profiles_comprehensive.csv')\n",
    "veg_season = pd.read_csv('vegetable_seasonality_sri_lanka_comprehensive.csv')\n",
    "recipes = pd.read_csv('sri_lankan_recipes_comprehensive.csv')\n",
    "hh_member_profiles = pd.read_csv('household_member_profiles.csv')\n",
    "\n",
    "# New price datasets\n",
    "wholesale_df = pd.read_csv('wholesale historical data.csv')\n",
    "market_df = pd.read_csv('vegetable_prices_pruned_features.csv')\n",
    "\n",
    "core_nutrients = ['Energ_Kcal', 'Protein_(g)', 'Fiber_TD_(g)', 'Iron_(mg)', \n",
    "                  'Potassium_(mg)', 'Sodium_(mg)', 'Vit_C_(mg)', 'Vit_A_RAE']\n",
    "available_nutrients = [col for col in core_nutrients if col in veggies.columns]\n",
    "\n",
    "for col in available_nutrients:\n",
    "    veggies[col] = pd.to_numeric(veggies[col], errors='coerce').fillna(0)\n",
    "\n",
    "veg_clean = veggies[['NDB_No', 'Shrt_Desc'] + available_nutrients].copy()\n",
    "veg_clean = veg_clean[veg_clean['Energ_Kcal'] > 0].drop_duplicates('NDB_No').reset_index(drop=True)\n",
    "\n",
    "def clean_string_for_matching(s):\n",
    "    if pd.isna(s): return \"\"\n",
    "    s = str(s).replace('\"', '').replace(\"'\", \"\").replace(',', ' ').replace('RAW', '')\n",
    "    return \"\".join(s.split()).upper()\n",
    "\n",
    "sri_local_codes = set(veg_season['usda_code'].apply(clean_string_for_matching).unique())\n",
    "\n",
    "# CotD 2024 mapping (Bulletin page 10)\n",
    "USDA_TO_COTD_MAP = {\n",
    "    'BEANS, GREEN': 'Bean (yard long)',\n",
    "    'OKRA, RAW': 'Okra',\n",
    "    'MORINGA LEAVES, RAW': 'Kathurumurunga',\n",
    "    'EGGPLANT, RAW': 'Eggplant',\n",
    "    'SWAMP CABBAGE': 'Kankun',\n",
    "    'WATERSPINACH, RAW': 'Kankun',\n",
    "    'BEET GREENS, RAW': 'Mukunuwenna',\n",
    "    'PLANTAIN, GREEN, RAW': 'Banana blossom',\n",
    "}\n",
    "\n",
    "COTD_VEGGIES = {\n",
    "    'Hambantota': ['Banana blossom', 'Bean (yard long)', 'Kathurumurunga', 'Okra'],\n",
    "    'Galle': ['Bean (yard long)', 'Eggplant', 'Kathurumurunga', 'Mukunuwenna', 'Okra'],\n",
    "    'Matara': ['Bean (yard long)', 'Kathurumurunga'],\n",
    "    # Add more districts as needed\n",
    "}\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 2. REAL PRICE LOOKUP FUNCTION\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def get_real_price(veg_name, month=None, year=None):\n",
    "    if month is None or year is None:\n",
    "        now = datetime.now(ZoneInfo(\"Asia/Colombo\"))\n",
    "        month = now.month\n",
    "        year = now.year\n",
    "    \n",
    "    veg_name = veg_name.split(',')[0].upper() if ',' in veg_name else veg_name.upper()\n",
    "    \n",
    "    # Primary: Dambulla wholesale\n",
    "    wholesale_match = wholesale_df[\n",
    "        (wholesale_df['Vegetable_Name'].str.upper() == veg_name) &\n",
    "        (wholesale_df['Month'] == month) & (wholesale_df['ISO_Year'] == year)\n",
    "    ]\n",
    "    if not wholesale_match.empty:\n",
    "        return wholesale_match['Avg_Weekly_Price'].mean()\n",
    "    \n",
    "    # Fallback: Colombo market\n",
    "    market_match = market_df[\n",
    "        (market_df['Vegetable'].str.upper() == veg_name) &\n",
    "        (market_df['Month'] == month) & (market_df['Year'] == year)\n",
    "    ]\n",
    "    if not market_match.empty:\n",
    "        return market_match['Weekly_Price'].mean()\n",
    "    \n",
    "    # Default CotD base (approx daily)\n",
    "    return 905.0 / 7\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 3. LTR TRAINING DATA GENERATION (with CotD feature)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def generate_ltr_training_data(num_users=150):\n",
    "    X_list, y_list, group_sizes = [], [], []\n",
    "    scaler = StandardScaler()\n",
    "    veg_matrix = scaler.fit_transform(veg_clean[available_nutrients])\n",
    "    \n",
    "    for i in range(num_users):\n",
    "        u = users.iloc[i % len(users)]\n",
    "        u_target = np.array([u.get('TEE', 2000) * 0.2 / 5 if n == 'Energ_Kcal' else 1.0 for n in available_nutrients])\n",
    "        old_scores = cosine_similarity(u_target.reshape(1, -1), veg_matrix)[0]\n",
    "        \n",
    "        top_idx = np.argsort(old_scores)[-10:]\n",
    "        pos_labels = np.linspace(4.0, 1.0, 10)\n",
    "        neg_idx = np.random.choice(len(veg_clean), 30, replace=False)\n",
    "        neg_labels = np.zeros(30)\n",
    "        \n",
    "        all_idx = np.concatenate([top_idx, neg_idx])\n",
    "        labels = np.concatenate([pos_labels, neg_labels])\n",
    "        user_feats = np.array([u['Age'], u.get('BMI', 22), u.get('TEE', 2000)])\n",
    "        \n",
    "        for idx in all_idx:\n",
    "            v = veg_clean.iloc[idx]\n",
    "            v_feats = v[available_nutrients].values\n",
    "            # CotD priority feature (same as inference)\n",
    "            v_name = clean_string_for_matching(v['Shrt_Desc'])\n",
    "            cotd_feature = 1 if USDA_TO_COTD_MAP.get(v_name, '') in COTD_VEGGIES.get('Hambantota', []) else 0\n",
    "            X_list.append(np.concatenate([user_feats, v_feats, [cotd_feature]]))\n",
    "            y_list.append(labels[np.where(all_idx == idx)[0][0]])\n",
    "        \n",
    "        group_sizes.append(len(all_idx))\n",
    "    \n",
    "    return np.array(X_list), np.array(y_list), group_sizes\n",
    "\n",
    "# Train XGBoost LTR\n",
    "print(\"Training proper XGBoost LTR model...\")\n",
    "X_train, y_train, groups = generate_ltr_training_data()\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtrain.set_group(groups)\n",
    "params = {\n",
    "    'objective': 'rank:pairwise',\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'eval_metric': 'ndcg@10',\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "ranker = xgb.train(params, dtrain, num_boost_round=200)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 4. RECIPE RECOMMENDATION LOGIC\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def recommend_recipes_safe(top_veggies, agg_info, district, num_recs=3):\n",
    "    matched = []\n",
    "    recipes['veg_list'] = recipes['vegetables_usda'].apply(\n",
    "        lambda x: [v.strip().upper() for v in ast.literal_eval(x)] if isinstance(x, str) else []\n",
    "    )\n",
    "   \n",
    "    for veg in top_veggies:\n",
    "        veg_name = veg.split(',')[0].upper()\n",
    "        candidates = recipes[recipes['veg_list'].apply(lambda x: any(veg_name in s for s in x))]\n",
    "       \n",
    "        if not candidates.empty:\n",
    "            rec = candidates.iloc[0]\n",
    "            total_weight = agg_info['total_weight']\n",
    "            # Use REAL price from historical data\n",
    "            real_price = get_real_price(veg)\n",
    "            total_cost = real_price * total_weight\n",
    "            if district in ['Hambantota', 'Matara', 'Galle']:\n",
    "                total_cost *= 0.95\n",
    "            \n",
    "            matched.append({\n",
    "                'recipe_name': rec['recipe_name'],\n",
    "                'total_cost_lkr': round(total_cost),\n",
    "                'scaled_servings': round(4 * total_weight),\n",
    "                'reason': f\"Uses {veg} - Southern Affordable Traditional Meal\"\n",
    "            })\n",
    "   \n",
    "    if not matched:\n",
    "        matched.append({\n",
    "            'recipe_name': \"Sri Lankan Mixed Vegetable Curry\",\n",
    "            'total_cost_lkr': round(250 * agg_info['total_weight']),\n",
    "            'scaled_servings': round(4 * agg_info['total_weight']),\n",
    "            'reason': \"Nutrient-dense traditional staple\"\n",
    "        })\n",
    "   \n",
    "    return sorted({r['recipe_name']: r for r in matched}.values(), key=lambda x: x['total_cost_lkr'])[:num_recs]\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 5. END-TO-END HOUSEHOLD PIPELINE\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def run_household_pipeline_final(hh_id, district):\n",
    "    members = hh_member_profiles[hh_member_profiles['Family_ID'] == hh_id]\n",
    "    if members.empty:\n",
    "        return None, \"Household not found\"\n",
    "   \n",
    "    total_weight = sum([0.16 if a < 8 else 0.29 if a >= 30 and members['Gender'].iloc[0] == 'Male' else 0.25 \n",
    "                        for a in members['Age']])\n",
    "    avg_tee = members['TEE'].mean()\n",
    "    avg_bmi = members['BMI'].mean()\n",
    "    \n",
    "    user_feats = np.array([members['Age'].mean(), avg_bmi, avg_tee])\n",
    "    X_test = []\n",
    "    filtered_veg = veg_clean[veg_clean['Shrt_Desc'].apply(lambda x: clean_string_for_matching(x) in sri_local_codes)].copy()\n",
    "   \n",
    "    for _, v in filtered_veg.iterrows():\n",
    "        v_feats = v[available_nutrients].values\n",
    "        v_name = clean_string_for_matching(v['Shrt_Desc'])\n",
    "        cotd_feature = 1 if USDA_TO_COTD_MAP.get(v_name, '') in COTD_VEGGIES.get(district, []) else 0\n",
    "        X_test.append(np.concatenate([user_feats, v_feats, [cotd_feature]]))\n",
    "   \n",
    "    dtest = xgb.DMatrix(np.array(X_test))\n",
    "    scores = ranker.predict(dtest)\n",
    "    top_idx = np.argsort(scores)[-5:][::-1]\n",
    "    recs = filtered_veg.iloc[top_idx].copy()\n",
    "   \n",
    "    risk = 0.30 if district == 'Hambantota' else 0.51 if district == 'Batticaloa' else 0.37\n",
    "    agg_cost = sum(get_real_price(recs.iloc[i]['Shrt_Desc']) for i in range(len(recs))) * total_weight / len(recs)\n",
    "   \n",
    "    meta = {'total_weight': total_weight, 'agg_cost': agg_cost}\n",
    "    recipes_list = recommend_recipes_safe(recs['Shrt_Desc'].tolist(), meta, district)\n",
    "   \n",
    "    return recs, {\n",
    "        'agg_tee': avg_tee,\n",
    "        'affordability_gap': agg_cost * risk,\n",
    "        'recipes': recipes_list,\n",
    "        'agg_cost': agg_cost\n",
    "    }\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 6. EXECUTE FOR DEMO\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "try:\n",
    "    tangalle_id = hh_member_profiles[hh_member_profiles['District'] == 'Hambantota']['Family_ID'].iloc[0]\n",
    "    final_recs, final_meta = run_household_pipeline_final(tangalle_id, \"Hambantota\")\n",
    "    \n",
    "    print(\"Success! XGBoost LTR + Recipes generated for Tangalle.\")\n",
    "    print(f\"Top Recommended Veggie: {final_recs['Shrt_Desc'].iloc[0]}\")\n",
    "    print(f\"Daily Affordability Gap: LKR {final_meta['affordability_gap']:.2f}\")\n",
    "    if final_meta['recipes']:\n",
    "        print(f\"Top Actionable Recipe: {final_meta['recipes'][0]['recipe_name']}\")\n",
    "        print(f\"Estimated Cost: LKR {final_meta['recipes'][0]['total_cost_lkr']}\")\n",
    "    else:\n",
    "        print(\"No recipes matched.\")\n",
    "    \n",
    "    final_recs.to_csv('household_recs_xgboost_ltr.csv', index=False)\n",
    "    pd.DataFrame(final_meta['recipes']).to_csv('household_recipes_final.csv', index=False)\n",
    "except Exception as e:\n",
    "    print(f\"Pipeline Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
