{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T17:14:02.820775500Z",
     "start_time": "2026-02-15T17:14:02.787389200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported.\")"
   ],
   "id": "3ea8c6727f84e6cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T17:14:02.914731900Z",
     "start_time": "2026-02-15T17:14:02.830790500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 2: Load the dataset\n",
    "file_path = '../data/preprocessed/vegetable_prices_clean.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ],
   "id": "1b5add8cdce5ea77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (4956, 43)\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   year week     vegetable  price Badulla_actual_class Hambantota_actual_class Jaffna_actual_class Kurunegala_actual_class Matale_actual_class Nuwara_Eliya_actual_class Ratnapura_actual_class  \\\n",
       "0  2010   W1  Bitter Gourd   52.4              drought                  normal             drought                 drought             drought                   drought                 normal   \n",
       "1  2010   W2  Bitter Gourd   58.6              drought                  normal             drought                 drought             drought                   drought                 normal   \n",
       "2  2010   W3  Bitter Gourd   58.6              drought                  normal             drought                 drought             drought                   drought                 normal   \n",
       "3  2010   W4  Bitter Gourd   58.6              drought                  normal             drought                 drought             drought                   drought                 normal   \n",
       "4  2010   W5  Bitter Gourd   54.3              drought              flood_risk             drought                 drought             drought                   drought                drought   \n",
       "\n",
       "   Badulla_precipitation  Hambantota_precipitation  Jaffna_precipitation  Kurunegala_precipitation  Matale_precipitation  Nuwara_Eliya_precipitation  Ratnapura_precipitation  Badulla_prob_drought  \\\n",
       "0               2.890000                  3.164286              0.341429                  1.027143              1.027143                    1.308571                 1.142857              0.995714   \n",
       "1               7.071429                  8.657143              5.664286                  9.607143              9.607143                    9.034286                 8.798571              0.987143   \n",
       "2               4.504286                  8.197143              0.081429                  1.887143              1.887143                    2.768571                 2.665714              0.988571   \n",
       "3               0.911429                  1.118571              0.181429                  0.450000              0.450000                    0.602857                 0.424286              0.997143   \n",
       "4               8.752857                 11.331429              0.035714                  3.317143              3.317143                    5.708571                 6.910000              0.978571   \n",
       "\n",
       "   Hambantota_prob_drought  Jaffna_prob_drought  Kurunegala_prob_drought  Matale_prob_drought  Nuwara_Eliya_prob_drought  Ratnapura_prob_drought  Badulla_prob_flood_risk  Hambantota_prob_flood_risk  \\\n",
       "0                 0.005714             0.982857                 0.984286             0.984286                   0.964286                0.032857                 0.000000                    0.000000   \n",
       "1                 0.030000             0.955714                 0.950000             0.947143                   0.944286                0.092857                 0.000000                    0.058571   \n",
       "2                 0.055714             0.997143                 0.990000             0.990000                   0.995714                0.087143                 0.000000                    0.001429   \n",
       "3                 0.014286             0.997143                 0.991429             0.992857                   0.988571                0.045714                 0.000000                    0.000000   \n",
       "4                 0.580000             0.995714                 0.988571             0.988571                   0.987143                0.567143                 0.008571                    0.094286   \n",
       "\n",
       "   Jaffna_prob_flood_risk  Kurunegala_prob_flood_risk  Matale_prob_flood_risk  Nuwara_Eliya_prob_flood_risk  Ratnapura_prob_flood_risk  Badulla_prob_normal  Hambantota_prob_normal  \\\n",
       "0                0.000000                    0.000000                0.000000                           0.0                   0.000000             0.004286                0.994286   \n",
       "1                0.004286                    0.002857                0.002857                           0.0                   0.001429             0.012857                0.911429   \n",
       "2                0.000000                    0.000000                0.000000                           0.0                   0.000000             0.011429                0.942857   \n",
       "3                0.000000                    0.000000                0.000000                           0.0                   0.000000             0.002857                0.985714   \n",
       "4                0.000000                    0.000000                0.000000                           0.0                   0.001429             0.012857                0.325714   \n",
       "\n",
       "   Jaffna_prob_normal  Kurunegala_prob_normal  Matale_prob_normal  Nuwara_Eliya_prob_normal  Ratnapura_prob_normal  USD_LKR_avg  RateChange_avg_%  week_num  year_week  \n",
       "0            0.017143                0.015714            0.015714                  0.035714               0.967143       114.40              0.00         1     201001  \n",
       "1            0.040000                0.047143            0.050000                  0.055714               0.905714       114.25             -0.13         2     201002  \n",
       "2            0.002857                0.010000            0.010000                  0.004286               0.912857       114.35              0.09         3     201003  \n",
       "3            0.002857                0.008571            0.007143                  0.011429               0.954286       114.65              0.26         4     201004  \n",
       "4            0.004286                0.011429            0.011429                  0.012857               0.431429       114.70              0.04         5     201005  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>vegetable</th>\n",
       "      <th>price</th>\n",
       "      <th>Badulla_actual_class</th>\n",
       "      <th>Hambantota_actual_class</th>\n",
       "      <th>Jaffna_actual_class</th>\n",
       "      <th>Kurunegala_actual_class</th>\n",
       "      <th>Matale_actual_class</th>\n",
       "      <th>Nuwara_Eliya_actual_class</th>\n",
       "      <th>Ratnapura_actual_class</th>\n",
       "      <th>Badulla_precipitation</th>\n",
       "      <th>Hambantota_precipitation</th>\n",
       "      <th>Jaffna_precipitation</th>\n",
       "      <th>Kurunegala_precipitation</th>\n",
       "      <th>Matale_precipitation</th>\n",
       "      <th>Nuwara_Eliya_precipitation</th>\n",
       "      <th>Ratnapura_precipitation</th>\n",
       "      <th>Badulla_prob_drought</th>\n",
       "      <th>Hambantota_prob_drought</th>\n",
       "      <th>Jaffna_prob_drought</th>\n",
       "      <th>Kurunegala_prob_drought</th>\n",
       "      <th>Matale_prob_drought</th>\n",
       "      <th>Nuwara_Eliya_prob_drought</th>\n",
       "      <th>Ratnapura_prob_drought</th>\n",
       "      <th>Badulla_prob_flood_risk</th>\n",
       "      <th>Hambantota_prob_flood_risk</th>\n",
       "      <th>Jaffna_prob_flood_risk</th>\n",
       "      <th>Kurunegala_prob_flood_risk</th>\n",
       "      <th>Matale_prob_flood_risk</th>\n",
       "      <th>Nuwara_Eliya_prob_flood_risk</th>\n",
       "      <th>Ratnapura_prob_flood_risk</th>\n",
       "      <th>Badulla_prob_normal</th>\n",
       "      <th>Hambantota_prob_normal</th>\n",
       "      <th>Jaffna_prob_normal</th>\n",
       "      <th>Kurunegala_prob_normal</th>\n",
       "      <th>Matale_prob_normal</th>\n",
       "      <th>Nuwara_Eliya_prob_normal</th>\n",
       "      <th>Ratnapura_prob_normal</th>\n",
       "      <th>USD_LKR_avg</th>\n",
       "      <th>RateChange_avg_%</th>\n",
       "      <th>week_num</th>\n",
       "      <th>year_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>W1</td>\n",
       "      <td>Bitter Gourd</td>\n",
       "      <td>52.4</td>\n",
       "      <td>drought</td>\n",
       "      <td>normal</td>\n",
       "      <td>drought</td>\n",
       "      <td>drought</td>\n",
       "      <td>drought</td>\n",
       "      <td>drought</td>\n",
       "      <td>normal</td>\n",
       "      <td>2.890000</td>\n",
       "      <td>3.164286</td>\n",
       "      <td>0.341429</td>\n",
       "      <td>1.027143</td>\n",
       "      <td>1.027143</td>\n",
       "      <td>1.308571</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.995714</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.982857</td>\n",
       "      <td>0.984286</td>\n",
       "      <td>0.984286</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.032857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.994286</td>\n",
       "      <td>0.017143</td>\n",
       "      <td>0.015714</td>\n",
       "      <td>0.015714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.967143</td>\n",
       "      <td>114.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>201001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>W2</td>\n",
       "      <td>Bitter Gourd</td>\n",
       "      <td>58.6</td>\n",
       "      <td>drought</td>\n",
       "      <td>normal</td>\n",
       "      <td>drought</td>\n",
       "      <td>drought</td>\n",
       "      <td>drought</td>\n",
       "      <td>drought</td>\n",
       "      <td>normal</td>\n",
       "      <td>7.071429</td>\n",
       "      <td>8.657143</td>\n",
       "      <td>5.664286</td>\n",
       "      <td>9.607143</td>\n",
       "      <td>9.607143</td>\n",
       "      <td>9.034286</td>\n",
       "      <td>8.798571</td>\n",
       "      <td>0.987143</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.955714</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.947143</td>\n",
       "      <td>0.944286</td>\n",
       "      <td>0.092857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058571</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.911429</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.047143</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.055714</td>\n",
       "      <td>0.905714</td>\n",
       "      <td>114.25</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>2</td>\n",
       "      <td>201002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>W3</td>\n",
       "      <td>Bitter Gourd</td>\n",
       "      <td>58.6</td>\n",
       "      <td>drought</td>\n",
       "      <td>normal</td>\n",
       "      <td>drought</td>\n",
       "      <td>drought</td>\n",
       "      <td>drought</td>\n",
       "      <td>drought</td>\n",
       "      <td>normal</td>\n",
       "      <td>4.504286</td>\n",
       "      <td>8.197143</td>\n",
       "      <td>0.081429</td>\n",
       "      <td>1.887143</td>\n",
       "      <td>1.887143</td>\n",
       "      <td>2.768571</td>\n",
       "      <td>2.665714</td>\n",
       "      <td>0.988571</td>\n",
       "      <td>0.055714</td>\n",
       "      <td>0.997143</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.995714</td>\n",
       "      <td>0.087143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.912857</td>\n",
       "      <td>114.35</td>\n",
       "      <td>0.09</td>\n",
       "      <td>3</td>\n",
       "      <td>201003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>W4</td>\n",
       "      <td>Bitter Gourd</td>\n",
       "      <td>58.6</td>\n",
       "      <td>drought</td>\n",
       "      <td>normal</td>\n",
       "      <td>drought</td>\n",
       "      <td>drought</td>\n",
       "      <td>drought</td>\n",
       "      <td>drought</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.911429</td>\n",
       "      <td>1.118571</td>\n",
       "      <td>0.181429</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.602857</td>\n",
       "      <td>0.424286</td>\n",
       "      <td>0.997143</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.997143</td>\n",
       "      <td>0.991429</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>0.988571</td>\n",
       "      <td>0.045714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>0.954286</td>\n",
       "      <td>114.65</td>\n",
       "      <td>0.26</td>\n",
       "      <td>4</td>\n",
       "      <td>201004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>W5</td>\n",
       "      <td>Bitter Gourd</td>\n",
       "      <td>54.3</td>\n",
       "      <td>drought</td>\n",
       "      <td>flood_risk</td>\n",
       "      <td>drought</td>\n",
       "      <td>drought</td>\n",
       "      <td>drought</td>\n",
       "      <td>drought</td>\n",
       "      <td>drought</td>\n",
       "      <td>8.752857</td>\n",
       "      <td>11.331429</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>3.317143</td>\n",
       "      <td>3.317143</td>\n",
       "      <td>5.708571</td>\n",
       "      <td>6.910000</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.995714</td>\n",
       "      <td>0.988571</td>\n",
       "      <td>0.988571</td>\n",
       "      <td>0.987143</td>\n",
       "      <td>0.567143</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.094286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.325714</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.431429</td>\n",
       "      <td>114.70</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5</td>\n",
       "      <td>201005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T17:14:03.068764500Z",
     "start_time": "2026-02-15T17:14:02.961787400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 3: Drop unnecessary columns (year, week)\n",
    "# Keep 'year_week' for sorting and temporal operations; will drop at the end.\n",
    "cols_to_drop = ['year', 'week']\n",
    "df.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "print(\"Columns after dropping 'year' and 'week':\")\n",
    "print(df.columns.tolist())"
   ],
   "id": "d6dfc8a25f9ae34f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after dropping 'year' and 'week':\n",
      "['vegetable', 'price', 'Badulla_actual_class', 'Hambantota_actual_class', 'Jaffna_actual_class', 'Kurunegala_actual_class', 'Matale_actual_class', 'Nuwara_Eliya_actual_class', 'Ratnapura_actual_class', 'Badulla_precipitation', 'Hambantota_precipitation', 'Jaffna_precipitation', 'Kurunegala_precipitation', 'Matale_precipitation', 'Nuwara_Eliya_precipitation', 'Ratnapura_precipitation', 'Badulla_prob_drought', 'Hambantota_prob_drought', 'Jaffna_prob_drought', 'Kurunegala_prob_drought', 'Matale_prob_drought', 'Nuwara_Eliya_prob_drought', 'Ratnapura_prob_drought', 'Badulla_prob_flood_risk', 'Hambantota_prob_flood_risk', 'Jaffna_prob_flood_risk', 'Kurunegala_prob_flood_risk', 'Matale_prob_flood_risk', 'Nuwara_Eliya_prob_flood_risk', 'Ratnapura_prob_flood_risk', 'Badulla_prob_normal', 'Hambantota_prob_normal', 'Jaffna_prob_normal', 'Kurunegala_prob_normal', 'Matale_prob_normal', 'Nuwara_Eliya_prob_normal', 'Ratnapura_prob_normal', 'USD_LKR_avg', 'RateChange_avg_%', 'week_num', 'year_week']\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T17:14:03.292396300Z",
     "start_time": "2026-02-15T17:14:03.272064100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 4: Encode climate actual class columns\n",
    "# Mapping: normal -> 0, flood_risk -> 1, drought -> -1\n",
    "class_cols = [\n",
    "    'Badulla_actual_class', 'Hambantota_actual_class', 'Jaffna_actual_class',\n",
    "    'Kurunegala_actual_class', 'Matale_actual_class', 'Nuwara_Eliya_actual_class',\n",
    "    'Ratnapura_actual_class'\n",
    "]\n",
    "\n",
    "class_mapping = {'normal': 0, 'flood_risk': 1, 'drought': -1}\n",
    "for col in class_cols:\n",
    "    df[col] = df[col].map(class_mapping)\n",
    "\n",
    "# Verify encoding\n",
    "print(\"Unique values in encoded class columns:\")\n",
    "for col in class_cols:\n",
    "    print(f\"{col}: {df[col].unique()}\")"
   ],
   "id": "3d389647722334a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in encoded class columns:\n",
      "Badulla_actual_class: [-1  0  1]\n",
      "Hambantota_actual_class: [ 0  1 -1]\n",
      "Jaffna_actual_class: [-1  0  1]\n",
      "Kurunegala_actual_class: [-1  0  1]\n",
      "Matale_actual_class: [-1  0  1]\n",
      "Nuwara_Eliya_actual_class: [-1  0  1]\n",
      "Ratnapura_actual_class: [ 0 -1  1]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T17:14:03.348603800Z",
     "start_time": "2026-02-15T17:14:03.334574800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 5: Encode vegetable column\n",
    "# Mapping: Bitter Gourd -> 1, Brinjals -> 2, Cabbage -> 3, Carrot -> 4, Pumpkin -> 5, Tomatoes -> 6\n",
    "veg_mapping = {\n",
    "    'Bitter Gourd': 1,\n",
    "    'Brinjals': 2,\n",
    "    'Cabbage': 3,\n",
    "    'Carrot': 4,\n",
    "    'Pumpkin': 5,\n",
    "    'Tomatoes': 6\n",
    "}\n",
    "df['vegetable'] = df['vegetable'].map(veg_mapping)\n",
    "\n",
    "print(\"Encoded vegetable values:\", df['vegetable'].unique())"
   ],
   "id": "5b5ed73a86df0477",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded vegetable values: [1 2 3 4 5 6]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T17:14:03.428730500Z",
     "start_time": "2026-02-15T17:14:03.413518200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 6: Sort data by vegetable and year_week to ensure correct temporal order\n",
    "# year_week is like 201001 (year + week number)\n",
    "df['year_week'] = df['year_week'].astype(int)\n",
    "df.sort_values(['vegetable', 'year_week'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Data sorted.\")"
   ],
   "id": "5ad6d5004fed2175",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sorted.\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T17:14:03.485692Z",
     "start_time": "2026-02-15T17:14:03.467164300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 7: Create lagged price features (1-week and 2-week lags)\n",
    "# Also absolute difference and percentage change from previous week.\n",
    "df['price_lag1'] = df.groupby('vegetable')['price'].shift(1)\n",
    "df['price_lag2'] = df.groupby('vegetable')['price'].shift(2)\n",
    "df['price_diff_abs'] = df['price'] - df['price_lag1']\n",
    "df['price_pct_change'] = (df['price'] - df['price_lag1']) / df['price_lag1'] * 100\n",
    "\n",
    "print(\"Lagged price features created.\")"
   ],
   "id": "b1412b9d93a1e39c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lagged price features created.\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T17:14:03.624119700Z",
     "start_time": "2026-02-15T17:14:03.487683200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 8: Rolling window statistics (4-week, using only t-4 to t-1)\n",
    "# We'll compute on shifted series to exclude current week.\n",
    "def rolling_feature(group, col, func, window=4):\n",
    "    # shift by 1 so that rolling uses t-1 to t-4\n",
    "    shifted = group[col].shift(1)\n",
    "    return shifted.rolling(window, min_periods=window).apply(func, raw=True)\n",
    "\n",
    "df['rolling_mean_4w'] = df.groupby('vegetable').apply(\n",
    "    lambda g: rolling_feature(g, 'price', np.mean)).reset_index(level=0, drop=True)\n",
    "df['rolling_std_4w'] = df.groupby('vegetable').apply(\n",
    "    lambda g: rolling_feature(g, 'price', np.std)).reset_index(level=0, drop=True)\n",
    "df['rolling_min_4w'] = df.groupby('vegetable').apply(\n",
    "    lambda g: rolling_feature(g, 'price', np.min)).reset_index(level=0, drop=True)\n",
    "df['rolling_max_4w'] = df.groupby('vegetable').apply(\n",
    "    lambda g: rolling_feature(g, 'price', np.max)).reset_index(level=0, drop=True)\n",
    "\n",
    "print(\"Rolling statistics created.\")"
   ],
   "id": "3c7e0fd765d9317c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling statistics created.\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T17:14:03.654135300Z",
     "start_time": "2026-02-15T17:14:03.624119700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 9: Lagged climate variables (1-week and 2-week lags for all climate-related columns)\n",
    "# Identify climate columns\n",
    "precip_cols = [c for c in df.columns if 'precipitation' in c]\n",
    "prob_drought_cols = [c for c in df.columns if 'prob_drought' in c]\n",
    "prob_flood_cols = [c for c in df.columns if 'prob_flood_risk' in c]\n",
    "prob_normal_cols = [c for c in df.columns if 'prob_normal' in c]\n",
    "# Encoded class columns (already done)\n",
    "actual_class_cols = class_cols\n",
    "\n",
    "climate_cols = precip_cols + prob_drought_cols + prob_flood_cols + prob_normal_cols + actual_class_cols\n",
    "\n",
    "# Create lags for each climate column, grouped by vegetable? No, climate is region-specific, not vegetable-specific.\n",
    "# But the data is repeated for each vegetable per week, so we can shift globally after sorting by week.\n",
    "# However, to be safe and consistent with time series, we'll shift based on the overall dataset order,\n",
    "# but we must ensure that the shift respects week boundaries across vegetables. Since all vegetables share the same weeks,\n",
    "# shifting globally is correct as long as the data is sorted by year_week. But shifting across vegetables would mix vegetables?\n",
    "# Actually, climate variables are the same for all vegetables in a given week, so shifting globally (without groupby) is fine\n",
    "# because the order is by week, and we want the previous week's climate values. There's no vegetable-specific climate.\n",
    "# So we can shift on the whole dataframe after sorting by year_week.\n",
    "df.sort_values('year_week', inplace=True)  # sort globally by week\n",
    "for col in climate_cols:\n",
    "    df[f'{col}_lag1'] = df[col].shift(1)\n",
    "    df[f'{col}_lag2'] = df[col].shift(2)\n",
    "\n",
    "# Restore original vegetable-wise order for subsequent operations\n",
    "df.sort_values(['vegetable', 'year_week'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Lagged climate variables created.\")"
   ],
   "id": "74ad51d95931d5b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lagged climate variables created.\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T17:14:03.689553900Z",
     "start_time": "2026-02-15T17:14:03.663339700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 10: Economic indicators\n",
    "# Lagged USD_LKR_avg (1 week, 4 weeks)\n",
    "df['USD_LKR_avg_lag1'] = df.groupby('vegetable')['USD_LKR_avg'].shift(1)\n",
    "df['USD_LKR_avg_lag4'] = df.groupby('vegetable')['USD_LKR_avg'].shift(4)\n",
    "\n",
    "# Rolling average of RateChange_avg_% (4-week, using past data)\n",
    "df['RateChange_roll4'] = df.groupby('vegetable')['RateChange_avg_%'].transform(\n",
    "    lambda x: x.shift(1).rolling(4, min_periods=4).mean()\n",
    ")\n",
    "\n",
    "# Interaction terms: USD_LKR_avg Ã— drought probability for each region, and USD_LKR_avg Ã— flood probability for each region\n",
    "# We'll create for all regions (7 regions) as an example.\n",
    "for region in ['Badulla', 'Hambantota', 'Jaffna', 'Kurunegala', 'Matale', 'Nuwara_Eliya', 'Ratnapura']:\n",
    "    drought_prob_col = f'{region}_prob_drought'\n",
    "    flood_prob_col = f'{region}_prob_flood_risk'\n",
    "    if drought_prob_col in df.columns:\n",
    "        df[f'USD_x_{region}_drought'] = df['USD_LKR_avg'] * df[drought_prob_col]\n",
    "    if flood_prob_col in df.columns:\n",
    "        df[f'USD_x_{region}_flood'] = df['USD_LKR_avg'] * df[flood_prob_col]\n",
    "\n",
    "print(\"Economic indicators and interactions created.\")"
   ],
   "id": "1c44077854c226db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Economic indicators and interactions created.\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T17:14:03.699138600Z",
     "start_time": "2026-02-15T17:14:03.689553900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 11: Seasonal & time features\n",
    "# Extract year from year_week (first 4 digits)\n",
    "df['year_num'] = (df['year_week'] // 100).astype(int)\n",
    "\n",
    "# Cyclic encoding of week_num (1-53)\n",
    "# Assuming week_num is already present and ranges 1-53\n",
    "week_max = 53\n",
    "df['week_sin'] = np.sin(2 * np.pi * df['week_num'] / week_max)\n",
    "df['week_cos'] = np.cos(2 * np.pi * df['week_num'] / week_max)\n",
    "\n",
    "print(\"Seasonal features added.\")"
   ],
   "id": "61f4bbad6e09f414",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seasonal features added.\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T17:14:03.731818200Z",
     "start_time": "2026-02-15T17:14:03.708157200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 12: Aggregated climate indices (current week)\n",
    "# Average precipitation across all regions\n",
    "precip_cols_list = precip_cols  # from earlier\n",
    "df['avg_precip'] = df[precip_cols_list].mean(axis=1)\n",
    "\n",
    "# Count of regions in drought (encoded class = -1)\n",
    "df['drought_count'] = (df[actual_class_cols] == -1).sum(axis=1)\n",
    "\n",
    "# Count of regions in flood (encoded class = 1)\n",
    "df['flood_count'] = (df[actual_class_cols] == 1).sum(axis=1)\n",
    "\n",
    "# Maximum precipitation\n",
    "df['max_precip'] = df[precip_cols_list].max(axis=1)\n",
    "\n",
    "# Minimum precipitation\n",
    "df['min_precip'] = df[precip_cols_list].min(axis=1)\n",
    "\n",
    "print(\"Aggregated climate indices created.\")"
   ],
   "id": "59f748173c73e52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated climate indices created.\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T17:14:03.755890200Z",
     "start_time": "2026-02-15T17:14:03.732948500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 13: Price relative features\n",
    "# Price divided by 4-week moving average (rolling_mean_4w)\n",
    "df['price_vs_ma'] = df['price'] / df['rolling_mean_4w']\n",
    "\n",
    "# Price minus 4-week moving average\n",
    "df['price_minus_ma'] = df['price'] - df['rolling_mean_4w']\n",
    "\n",
    "print(\"Price relative features created.\")"
   ],
   "id": "64b6b7f8cd242e8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price relative features created.\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T17:14:03.796747900Z",
     "start_time": "2026-02-15T17:14:03.757396100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 14: Event-based features - weeks since last drought and flood for each region\n",
    "# Create a weekly aggregated dataframe (unique weeks) with region classes\n",
    "weekly_df = df[['year_week'] + actual_class_cols].drop_duplicates().copy()\n",
    "weekly_df.sort_values('year_week', inplace=True)\n",
    "weekly_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Add a global week counter (0,1,2,...) for easy difference calculation\n",
    "weekly_df['global_week'] = np.arange(len(weekly_df))\n",
    "\n",
    "# For each region, compute weeks since last drought and last flood\n",
    "for region in actual_class_cols:\n",
    "    region_name = region.replace('_actual_class', '')\n",
    "\n",
    "    # --- Drought (class = -1) ---\n",
    "    # Boolean mask for drought occurrences\n",
    "    drought_mask = weekly_df[region] == -1\n",
    "\n",
    "    # Create a Series with global_week where drought occurred, otherwise NaN\n",
    "    drought_week_series = weekly_df['global_week'].where(drought_mask)\n",
    "\n",
    "    # Forward fill to get the most recent drought week for each subsequent week\n",
    "    last_drought_global = drought_week_series.ffill()\n",
    "\n",
    "    # Weeks since last drought = current global_week - last drought global_week\n",
    "    # If no prior drought, result is NaN\n",
    "    weekly_df[f'{region_name}_weeks_since_drought'] = weekly_df['global_week'] - last_drought_global\n",
    "\n",
    "    # --- Flood (class = 1) ---\n",
    "    flood_mask = weekly_df[region] == 1\n",
    "    flood_week_series = weekly_df['global_week'].where(flood_mask)\n",
    "    last_flood_global = flood_week_series.ffill()\n",
    "    weekly_df[f'{region_name}_weeks_since_flood'] = weekly_df['global_week'] - last_flood_global\n",
    "\n",
    "# Keep only necessary columns for merging\n",
    "weeks_cols = ['year_week'] + [c for c in weekly_df.columns if 'weeks_since' in c]\n",
    "weekly_events = weekly_df[weeks_cols]\n",
    "\n",
    "# Merge back to main dataframe (each vegetable row gets the same weekly value)\n",
    "df = df.merge(weekly_events, on='year_week', how='left')\n",
    "\n",
    "print(\"Event-based features (weeks since drought/flood) created.\")"
   ],
   "id": "ae838b471f991610",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event-based features (weeks since drought/flood) created.\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T17:14:03.827166400Z",
     "start_time": "2026-02-15T17:14:03.796747900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 15: Cumulative precipitation over past N weeks (e.g., 4 weeks)\n",
    "# For each region, compute rolling sum of precipitation over last 4 weeks (excluding current week)\n",
    "for region in ['Badulla', 'Hambantota', 'Jaffna', 'Kurunegala', 'Matale', 'Nuwara_Eliya', 'Ratnapura']:\n",
    "    precip_col = f'{region}_precipitation'\n",
    "    # Shift by 1 to exclude current week, then rolling sum of 4\n",
    "    df[f'{region}_precip_cum4'] = df.groupby('vegetable')[precip_col].transform(\n",
    "        lambda x: x.shift(1).rolling(4, min_periods=4).sum()\n",
    "    )\n",
    "\n",
    "print(\"Cumulative precipitation features added.\")"
   ],
   "id": "ff32745df36e8bc1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative precipitation features added.\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T17:14:03.837133100Z",
     "start_time": "2026-02-15T17:14:03.827166400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 16: Interaction & polynomial features (optional, for linear models)\n",
    "# USD_LKR_avg Ã— average precipitation\n",
    "df['USD_x_avg_precip'] = df['USD_LKR_avg'] * df['avg_precip']\n",
    "\n",
    "# USD_LKR_avg Ã— drought_count\n",
    "df['USD_x_drought_count'] = df['USD_LKR_avg'] * df['drought_count']\n",
    "\n",
    "# USD_LKR_avg Ã— flood_count\n",
    "df['USD_x_flood_count'] = df['USD_LKR_avg'] * df['flood_count']\n",
    "\n",
    "# Squared terms\n",
    "df['USD_sq'] = df['USD_LKR_avg'] ** 2\n",
    "df['avg_precip_sq'] = df['avg_precip'] ** 2\n",
    "\n",
    "print(\"Selected interaction and polynomial features created.\")"
   ],
   "id": "2641acd93049e14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected interaction and polynomial features created.\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T17:14:03.869406900Z",
     "start_time": "2026-02-15T17:14:03.845141200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 17: Drop year_week column as per requirement\n",
    "df.drop(columns=['year_week'], inplace=True)\n",
    "\n",
    "print(\"Final columns:\")\n",
    "print(df.columns.tolist())\n",
    "print(f\"Final shape: {df.shape}\")"
   ],
   "id": "b2b85b924a590e13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final columns:\n",
      "['vegetable', 'price', 'Badulla_actual_class', 'Hambantota_actual_class', 'Jaffna_actual_class', 'Kurunegala_actual_class', 'Matale_actual_class', 'Nuwara_Eliya_actual_class', 'Ratnapura_actual_class', 'Badulla_precipitation', 'Hambantota_precipitation', 'Jaffna_precipitation', 'Kurunegala_precipitation', 'Matale_precipitation', 'Nuwara_Eliya_precipitation', 'Ratnapura_precipitation', 'Badulla_prob_drought', 'Hambantota_prob_drought', 'Jaffna_prob_drought', 'Kurunegala_prob_drought', 'Matale_prob_drought', 'Nuwara_Eliya_prob_drought', 'Ratnapura_prob_drought', 'Badulla_prob_flood_risk', 'Hambantota_prob_flood_risk', 'Jaffna_prob_flood_risk', 'Kurunegala_prob_flood_risk', 'Matale_prob_flood_risk', 'Nuwara_Eliya_prob_flood_risk', 'Ratnapura_prob_flood_risk', 'Badulla_prob_normal', 'Hambantota_prob_normal', 'Jaffna_prob_normal', 'Kurunegala_prob_normal', 'Matale_prob_normal', 'Nuwara_Eliya_prob_normal', 'Ratnapura_prob_normal', 'USD_LKR_avg', 'RateChange_avg_%', 'week_num', 'price_lag1', 'price_lag2', 'price_diff_abs', 'price_pct_change', 'rolling_mean_4w', 'rolling_std_4w', 'rolling_min_4w', 'rolling_max_4w', 'Badulla_precipitation_lag1', 'Badulla_precipitation_lag2', 'Hambantota_precipitation_lag1', 'Hambantota_precipitation_lag2', 'Jaffna_precipitation_lag1', 'Jaffna_precipitation_lag2', 'Kurunegala_precipitation_lag1', 'Kurunegala_precipitation_lag2', 'Matale_precipitation_lag1', 'Matale_precipitation_lag2', 'Nuwara_Eliya_precipitation_lag1', 'Nuwara_Eliya_precipitation_lag2', 'Ratnapura_precipitation_lag1', 'Ratnapura_precipitation_lag2', 'Badulla_prob_drought_lag1', 'Badulla_prob_drought_lag2', 'Hambantota_prob_drought_lag1', 'Hambantota_prob_drought_lag2', 'Jaffna_prob_drought_lag1', 'Jaffna_prob_drought_lag2', 'Kurunegala_prob_drought_lag1', 'Kurunegala_prob_drought_lag2', 'Matale_prob_drought_lag1', 'Matale_prob_drought_lag2', 'Nuwara_Eliya_prob_drought_lag1', 'Nuwara_Eliya_prob_drought_lag2', 'Ratnapura_prob_drought_lag1', 'Ratnapura_prob_drought_lag2', 'Badulla_prob_flood_risk_lag1', 'Badulla_prob_flood_risk_lag2', 'Hambantota_prob_flood_risk_lag1', 'Hambantota_prob_flood_risk_lag2', 'Jaffna_prob_flood_risk_lag1', 'Jaffna_prob_flood_risk_lag2', 'Kurunegala_prob_flood_risk_lag1', 'Kurunegala_prob_flood_risk_lag2', 'Matale_prob_flood_risk_lag1', 'Matale_prob_flood_risk_lag2', 'Nuwara_Eliya_prob_flood_risk_lag1', 'Nuwara_Eliya_prob_flood_risk_lag2', 'Ratnapura_prob_flood_risk_lag1', 'Ratnapura_prob_flood_risk_lag2', 'Badulla_prob_normal_lag1', 'Badulla_prob_normal_lag2', 'Hambantota_prob_normal_lag1', 'Hambantota_prob_normal_lag2', 'Jaffna_prob_normal_lag1', 'Jaffna_prob_normal_lag2', 'Kurunegala_prob_normal_lag1', 'Kurunegala_prob_normal_lag2', 'Matale_prob_normal_lag1', 'Matale_prob_normal_lag2', 'Nuwara_Eliya_prob_normal_lag1', 'Nuwara_Eliya_prob_normal_lag2', 'Ratnapura_prob_normal_lag1', 'Ratnapura_prob_normal_lag2', 'Badulla_actual_class_lag1', 'Badulla_actual_class_lag2', 'Hambantota_actual_class_lag1', 'Hambantota_actual_class_lag2', 'Jaffna_actual_class_lag1', 'Jaffna_actual_class_lag2', 'Kurunegala_actual_class_lag1', 'Kurunegala_actual_class_lag2', 'Matale_actual_class_lag1', 'Matale_actual_class_lag2', 'Nuwara_Eliya_actual_class_lag1', 'Nuwara_Eliya_actual_class_lag2', 'Ratnapura_actual_class_lag1', 'Ratnapura_actual_class_lag2', 'USD_LKR_avg_lag1', 'USD_LKR_avg_lag4', 'RateChange_roll4', 'USD_x_Badulla_drought', 'USD_x_Badulla_flood', 'USD_x_Hambantota_drought', 'USD_x_Hambantota_flood', 'USD_x_Jaffna_drought', 'USD_x_Jaffna_flood', 'USD_x_Kurunegala_drought', 'USD_x_Kurunegala_flood', 'USD_x_Matale_drought', 'USD_x_Matale_flood', 'USD_x_Nuwara_Eliya_drought', 'USD_x_Nuwara_Eliya_flood', 'USD_x_Ratnapura_drought', 'USD_x_Ratnapura_flood', 'year_num', 'week_sin', 'week_cos', 'avg_precip', 'drought_count', 'flood_count', 'max_precip', 'min_precip', 'price_vs_ma', 'price_minus_ma', 'Badulla_weeks_since_drought', 'Badulla_weeks_since_flood', 'Hambantota_weeks_since_drought', 'Hambantota_weeks_since_flood', 'Jaffna_weeks_since_drought', 'Jaffna_weeks_since_flood', 'Kurunegala_weeks_since_drought', 'Kurunegala_weeks_since_flood', 'Matale_weeks_since_drought', 'Matale_weeks_since_flood', 'Nuwara_Eliya_weeks_since_drought', 'Nuwara_Eliya_weeks_since_flood', 'Ratnapura_weeks_since_drought', 'Ratnapura_weeks_since_flood', 'Badulla_precip_cum4', 'Hambantota_precip_cum4', 'Jaffna_precip_cum4', 'Kurunegala_precip_cum4', 'Matale_precip_cum4', 'Nuwara_Eliya_precip_cum4', 'Ratnapura_precip_cum4', 'USD_x_avg_precip', 'USD_x_drought_count', 'USD_x_flood_count', 'USD_sq', 'avg_precip_sq']\n",
      "Final shape: (4956, 171)\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T17:14:04.731115600Z",
     "start_time": "2026-02-15T17:14:03.870407300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 18: Save the engineered dataset\n",
    "output_dir = '../data/feature_engineered'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'vegetable_prices_fe.csv')\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Feature-engineered data saved to: {output_path}\")"
   ],
   "id": "8724102fefc62ff0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature-engineered data saved to: ../data/feature_engineered\\vegetable_prices_fe.csv\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T17:14:05.917329700Z",
     "start_time": "2026-02-15T17:14:05.125704300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell: Clean dataset and save to original file\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the feature-engineered dataset\n",
    "file_path = '../data/feature_engineered/vegetable_prices_fe.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CLEANING DATASET - REMOVING ALL MISSING VALUES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Original stats\n",
    "original_rows = len(df)\n",
    "print(f\"Original rows: {original_rows}\")\n",
    "\n",
    "# Remove all rows with any missing values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Verify no missing values remain\n",
    "missing_check = df_clean.isnull().sum().sum()\n",
    "print(f\"Rows after cleaning: {len(df_clean)}\")\n",
    "print(f\"Rows removed: {original_rows - len(df_clean)}\")\n",
    "print(f\"Removal percentage: {(1 - len(df_clean)/original_rows)*100:.2f}%\")\n",
    "print(f\"Missing values remaining: {missing_check}\")\n",
    "\n",
    "# Check per vegetable balance\n",
    "veg_counts = df_clean['vegetable'].value_counts().sort_index()\n",
    "veg_names = {1:'Bitter Gourd', 2:'Brinjals', 3:'Cabbage',\n",
    "             4:'Carrot', 5:'Pumpkin', 6:'Tomatoes'}\n",
    "\n",
    "print(\"\\nðŸ“Š Rows per vegetable after cleaning:\")\n",
    "for veg, count in veg_counts.items():\n",
    "    print(f\"  {veg_names[veg]}: {count} rows\")\n",
    "\n",
    "# Save directly to the original file (overwrite)\n",
    "df_clean.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"\\nðŸ’¾ File successfully overwritten: {file_path}\")\n",
    "print(f\"   Final shape: {df_clean.shape[0]} rows, {df_clean.shape[1]} columns\")\n",
    "\n",
    "# Quick verification\n",
    "test_df = pd.read_csv(file_path)\n",
    "print(f\"âœ… Verified: {test_df.shape[0]} rows, {test_df.shape[1]} columns\")\n",
    "print(f\"âœ… No missing values: {test_df.isnull().sum().sum() == 0}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… DATASET CLEANED AND SAVED\")\n",
    "print(\"=\"*60)"
   ],
   "id": "95b12b46aac927e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CLEANING DATASET - REMOVING ALL MISSING VALUES\n",
      "============================================================\n",
      "Original rows: 4956\n",
      "Rows after cleaning: 4842\n",
      "Rows removed: 114\n",
      "Removal percentage: 2.30%\n",
      "Missing values remaining: 0\n",
      "\n",
      "ðŸ“Š Rows per vegetable after cleaning:\n",
      "  Bitter Gourd: 807 rows\n",
      "  Brinjals: 807 rows\n",
      "  Cabbage: 807 rows\n",
      "  Carrot: 807 rows\n",
      "  Pumpkin: 807 rows\n",
      "  Tomatoes: 807 rows\n",
      "\n",
      "ðŸ’¾ File successfully overwritten: ../data/feature_engineered/vegetable_prices_fe.csv\n",
      "   Final shape: 4842 rows, 171 columns\n",
      "âœ… Verified: 4842 rows, 171 columns\n",
      "âœ… No missing values: True\n",
      "\n",
      "============================================================\n",
      "âœ… DATASET CLEANED AND SAVED\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
