{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bfde8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training proper XGBoost LTR model...\n",
      "Success! XGBoost LTR + Recipes generated for Tangalle.\n",
      "Top Recommended Veggie: CASSAVA,RAW\n",
      "Top Scaled Recipe: Pumpkin Curry Variation 1 (LKR 322.32)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import ast\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. LOAD & ROBUSTLY CLEAN DATASETS\n",
    "veggies = pd.read_csv('vegetables_USDA.csv')\n",
    "users = pd.read_csv('user_profiles_enhanced.csv')\n",
    "dist_profiles = pd.read_csv('final_datasets/district_profiles_comprehensive.csv')\n",
    "veg_season = pd.read_csv('vegetable_seasonality_sri_lanka_comprehensive.csv')\n",
    "recipes = pd.read_csv('sri_lankan_recipes_comprehensive.csv')\n",
    "hh_member_profiles = pd.read_csv('household_member_profiles.csv')\n",
    "\n",
    "# Nutrients used for feature engineering\n",
    "core_nutrients = ['Energ_Kcal', 'Protein_(g)', 'Fiber_TD_(g)', 'Iron_(mg)', 'Potassium_(mg)', 'Sodium_(mg)', 'Vit_C_(mg)', 'Vit_A_RAE']\n",
    "available_nutrients = [col for col in core_nutrients if col in veggies.columns]\n",
    "\n",
    "# Ensure data is clean for similarity teacher logic\n",
    "for col in available_nutrients:\n",
    "    veggies[col] = pd.to_numeric(veggies[col], errors='coerce').fillna(0)\n",
    "veg_clean = veggies.drop_duplicates('NDB_No').reset_index(drop=True)\n",
    "\n",
    "def clean_string_for_matching(s):\n",
    "    if pd.isna(s): return \"\"\n",
    "    s = str(s).replace('\"', '').replace(\"'\", \"\").replace(',', ' ').replace('RAW', '')\n",
    "    return \"\".join(s.split()).upper()\n",
    "\n",
    "sri_local_codes = set(veg_season['usda_code'].apply(clean_string_for_matching).unique())\n",
    "\n",
    "# 2. PROPER LTR DATA GENERATION (Using Cosine Similarity as a Teacher)\n",
    "def generate_ltr_training_data(num_users=200):\n",
    "    \"\"\"\n",
    "    Creates a proper LTR training set with (User + Veggie) fused features.\n",
    "    Labels (relevance) are generated using your existing cosine logic.\n",
    "    \"\"\"\n",
    "    X_list, y_list, group_sizes = [], [], []\n",
    "    scaler = StandardScaler()\n",
    "    veg_matrix = scaler.fit_transform(veg_clean[available_nutrients])\n",
    "    \n",
    "    for i in range(num_users):\n",
    "        u = users.iloc[i % len(users)]\n",
    "        # Target based on user TEE and standard RDA\n",
    "        u_target = np.array([u.get('TEE', 2000) * 0.2 / 5 if n == 'Energ_Kcal' else 1.0 for n in available_nutrients])\n",
    "        \n",
    "        # Ground Truth Teacher Signal\n",
    "        old_scores = cosine_similarity(u_target.reshape(1, -1), veg_matrix)[0]\n",
    "        \n",
    "        top_idx = np.argsort(old_scores)[-10:]\n",
    "        pos_labels = np.linspace(4.0, 1.0, 10) # Higher rank = higher label\n",
    "        neg_idx = np.random.choice(len(veg_clean), 30, replace=False)\n",
    "        neg_labels = np.zeros(30)\n",
    "        \n",
    "        all_idx = np.concatenate([top_idx, neg_idx])\n",
    "        labels = np.concatenate([pos_labels, neg_labels])\n",
    "        user_feats = np.array([u['Age'], u.get('BMI', 22), u.get('TEE', 2000)])\n",
    "        \n",
    "        for idx in all_idx:\n",
    "            v_feats = veg_clean.iloc[idx][available_nutrients].values\n",
    "            X_list.append(np.concatenate([user_feats, v_feats]))\n",
    "            y_list.append(labels[np.where(all_idx == idx)[0][0]])\n",
    "        group_sizes.append(len(all_idx))\n",
    "    return np.array(X_list), np.array(y_list), group_sizes\n",
    "\n",
    "# 3. TRAIN REAL XGBRANKER\n",
    "print(\"Training proper XGBoost LTR model...\")\n",
    "X_train, y_train, groups = generate_ltr_training_data()\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtrain.set_group(groups)\n",
    "\n",
    "params = {\n",
    "    'objective': 'rank:pairwise', # Optimization for relative ranking\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'eval_metric': 'ndcg@10',\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "ranker = xgb.train(params, dtrain, num_boost_round=300)\n",
    "\n",
    "# 4. LAYER 5: RECIPE RECOMMENDATION & SCALING\n",
    "COTD_RATIOS = {'child': 0.16, 'adolescent_girl': 0.30, 'adult_male': 0.29, 'adult_female': 0.25}\n",
    "\n",
    "def recommend_recipes(top_veggies, agg_info, district, num_recs=3):\n",
    "    \"\"\"Matches recipes to top ranked veggies, filters traditional cuisine, and scales portions.\"\"\"\n",
    "    matched_rec = []\n",
    "    # Use ast.literal_eval for safe parsing of main vegetable strings\n",
    "    recipes['main_veg_clean'] = recipes['vegetables_usda'].apply(\n",
    "        lambda x: [clean_string_for_matching(v) for v in ast.literal_eval(x)] if isinstance(x, str) else []\n",
    "    )\n",
    "    \n",
    "    for veg in top_veggies:\n",
    "        veg_cleaned = clean_string_for_matching(veg)\n",
    "        candidates = recipes[(recipes['main_veg_clean'].apply(lambda x: veg_cleaned in x)) & \n",
    "                             (recipes['cuisine_type'].str.contains('Traditional|Sri Lankan', case=False, na=False))]\n",
    "        \n",
    "        if not candidates.empty:\n",
    "            candidates = candidates.sort_values(['popularity_score', 'traditional_rating'], ascending=False).head(2)\n",
    "            for _, rec in candidates.iterrows():\n",
    "                # Scale for household size using total_weight\n",
    "                scaled_servings = rec['servings'] * agg_info['total_weight']\n",
    "                total_cost = rec['cost_per_serving_lkr'] * scaled_servings\n",
    "                \n",
    "                # Southern district cost refinement\n",
    "                if district in ['Hambantota', 'Matara', 'Galle']: total_cost *= 0.95 \n",
    "                \n",
    "                matched_rec.append({\n",
    "                    'recipe_name': rec['recipe_name'],\n",
    "                    'scaled_servings': round(scaled_servings),\n",
    "                    'total_cost_lkr': round(total_cost, 2),\n",
    "                    'ingredients': rec['other_ingredients'],\n",
    "                    'reason': f\"Uses {veg} - Southern Affordable Traditional Meal\"\n",
    "                })\n",
    "    return sorted({r['recipe_name']: r for r in matched_rec}.values(), key=lambda x: x['total_cost_lkr'])[:num_recs]\n",
    "\n",
    "# 5. END-TO-END PIPELINE (Household -> LTR -> Recipes)\n",
    "def run_household_pipeline_ltr_final(hh_id, district):\n",
    "    # Aggregation logic with CotD ratios\n",
    "    members = hh_member_profiles[hh_member_profiles['Family_ID'] == hh_id]\n",
    "    if members.empty: return None, \"HH Not Found\"\n",
    "    \n",
    "    total_weight = sum([COTD_RATIOS['child'] if a < 8 else COTD_RATIOS['adult_male'] for a in members['Age']])\n",
    "    avg_tee, avg_bmi = members['TEE'].mean(), members['BMI'].mean()\n",
    "    \n",
    "    # XGBRanker Inference Features\n",
    "    user_feats = np.array([members['Age'].mean(), avg_bmi, avg_tee])\n",
    "    X_test = []\n",
    "    filtered_veg = veg_clean[veg_clean['Shrt_Desc'].apply(lambda x: clean_string_for_matching(x) in sri_local_codes)].copy()\n",
    "    \n",
    "    for _, v in filtered_veg.iterrows():\n",
    "        X_test.append(np.concatenate([user_feats, v[available_nutrients].values]))\n",
    "        \n",
    "    dtest = xgb.DMatrix(np.array(X_test))\n",
    "    scores = ranker.predict(dtest)\n",
    "    top_idx = np.argsort(scores)[-5:][::-1]\n",
    "    recs = filtered_veg.iloc[top_idx].copy()\n",
    "    \n",
    "    # Affordability Refinement (CotD Page 11)\n",
    "    risk = 0.30 if district == 'Hambantota' else 0.51 if district == 'Batticaloa' else 0.37\n",
    "    agg_cost = 905 * total_weight\n",
    "    \n",
    "    # Layer 5: Scaling Actionable Recipes\n",
    "    recipes_list = recommend_recipes(recs['Shrt_Desc'].tolist(), {'total_weight': total_weight}, district)\n",
    "    \n",
    "    return recs, {\n",
    "        'agg_tee': avg_tee,\n",
    "        'affordability_gap': agg_cost * risk,\n",
    "        'recipes': recipes_list\n",
    "    }\n",
    "\n",
    "# 6. FINAL EXECUTION (Hambantota/Tangalle)\n",
    "try:\n",
    "    tangalle_id = hh_member_profiles[hh_member_profiles['District'] == 'Hambantota']['Family_ID'].iloc[0]\n",
    "    final_recs, final_meta = run_household_pipeline_ltr_final(tangalle_id, \"Hambantota\")\n",
    "    \n",
    "    print(\"Success! XGBoost LTR + Recipes generated for Tangalle.\")\n",
    "    print(f\"Top Recommended Veggie: {final_recs['Shrt_Desc'].iloc[0]}\")\n",
    "    print(f\"Top Scaled Recipe: {final_meta['recipes'][0]['recipe_name']} (LKR {final_meta['recipes'][0]['total_cost_lkr']})\")\n",
    "    \n",
    "    final_recs.to_csv('household_recs_xgboost_ltr.csv', index=False)\n",
    "    pd.DataFrame(final_meta['recipes']).to_csv('household_recipes_final.csv', index=False)\n",
    "except Exception as e:\n",
    "    print(f\"Pipeline Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
